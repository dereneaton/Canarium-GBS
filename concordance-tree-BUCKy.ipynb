{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canarium bucky analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import ipyparallel\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p analysis_bucky/testlocs4/\n",
    "mkdir -p analysis_bucky/testlocs5/\n",
    "mkdir -p analysis_bucky/testlocs6/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for hypothesis 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D4 = {\"out\": \"D14269\",\n",
    "      \"K1\": \"SF328\",\n",
    "      \"K2\": \"D14483\",\n",
    "      \"K3\": \"D14478\",\n",
    "      \"K4\": \"SF224\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for hypothesis 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D5 = {\"out\": \"D14269\",\n",
    "      \"K1\": \"SF328\",\n",
    "      \"K2\": \"D14505\",\n",
    "      \"K3\": \"D14478\",\n",
    "      \"K4\": \"D14483\",\n",
    "      \"K5\": \"SF224\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for hypothesis 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D6 = {\"out\": \"D14269\",\n",
    "      \"K1\": \"SF328\",\n",
    "      \"K2\": \"D14483\",\n",
    "      \"K3\": \"D14478\",\n",
    "      \"K4\": \"D14505\",\n",
    "      \"K5\": \"D12950\",\n",
    "      \"K6\": \"SF224\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to embed mrbayes block in nexus files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEXBLOCK = \"\"\"\\\n",
    "#NEXUS\n",
    "begin data;\n",
    "dimensions ntax={} nchar={};\n",
    "format datatype=dna interleave=yes gap=- missing=N;\n",
    "matrix\n",
    "{}\n",
    "    ;\n",
    "\n",
    "begin mrbayes;\n",
    "set autoclose=yes nowarn=yes;\n",
    "lset nst=6 rates=gamma;\n",
    "outgroup {};\n",
    "mcmc ngen=4000000 samplefreq=4000 printfreq=40000000;\n",
    "sump burnin=1000000;\n",
    "sumt burnin=1000000;\n",
    "end;\n",
    "\"\"\"\n",
    "\n",
    "def nexmake(hdict, nloci, outgname, name):\n",
    "    ## open nexus file handle\n",
    "    outloc = open(\"analysis_bucky/testlocs{}/{}.nex\".format(name, str(nloci)), 'w')\n",
    "    \n",
    "    ## create matrix as a string\n",
    "    matrix = \"\"\n",
    "    for i in hdict.items():\n",
    "        matrix += \"{:<10} {}\\n\".format(i[0][:10], i[1])\n",
    "    \n",
    "    ## write nexus block\n",
    "    outloc.write(NEXBLOCK.format(len(hdict), \n",
    "                                 len(hdict.values()[0]),\n",
    "                                 matrix,\n",
    "                                 outgname,\n",
    "                                 ))\n",
    "    outloc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to count informative sites in RAD locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## parse it\n",
    "AMBIGS = {\"R\": (\"G\", \"A\"),\n",
    "          \"K\": (\"G\", \"T\"),\n",
    "          \"S\": (\"G\", \"C\"),\n",
    "          \"Y\": (\"T\", \"C\"),\n",
    "          \"W\": (\"T\", \"A\"),\n",
    "          \"M\": (\"C\", \"A\")}\n",
    "    \n",
    "def unstruct(amb):\n",
    "    \" returns bases from ambiguity code\"\n",
    "    if amb in AMBIGS:\n",
    "        return AMBIGS.get(amb)\n",
    "    else:\n",
    "        return (amb, amb)\n",
    "            \n",
    "\n",
    "def resolveambig(subseq):\n",
    "    \"\"\" randomly resolves iupac hetero codes \"\"\"\n",
    "    N = []\n",
    "    for col in subseq:\n",
    "        N.append([unstruct(i)[np.random.binomial(1, 0.5)] for i in col])\n",
    "    return np.array(N)\n",
    "    \n",
    "    \n",
    "def newPIS(seqsamp):\n",
    "    \"\"\" filters for loci with >= 2 PIS \"\"\"\n",
    "    counts = [Counter(col) for col in seqsamp.T if not (\"-\" in col or \"N\" in col)]\n",
    "    pis = [i.most_common(2)[1][1] > 1 for i in counts if len(i.most_common(2))>1]\n",
    "    if sum(pis) >= 2:\n",
    "        return sum(pis)\n",
    "    else:\n",
    "        return 0      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to parse RAD loci\n",
    "Filters for only loci that are informative and have all samples in a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseloci(loci, hdict, name):\n",
    "    \"\"\" \n",
    "    This parses the .loci file format produced by ipyrad v.0.3.*\n",
    "    \"\"\"\n",
    "    ## keep track of how many loci pass\n",
    "    nloci = 0\n",
    "    \n",
    "    ## create subsampled data set\n",
    "    for loc in loci:\n",
    "        dat = loc.split(\"\\n\")[:-1]\n",
    "\n",
    "        ## if all tip samples have data in this locus\n",
    "        names = [i.split()[0] for i in dat]\n",
    "        seqs = np.array([list(i.split()[1]) for i in dat])\n",
    "\n",
    "        ## check that locus has required samples for each subtree\n",
    "        if all([i in names for i in hdict.values()]):\n",
    "            seqsamp = seqs[[names.index(tax) for tax in hdict.values()]]\n",
    "            seqsamp = resolveambig(seqsamp)\n",
    "            pis = newPIS(seqsamp)\n",
    "            if pis:\n",
    "                nloci += 1\n",
    "                ## remove invariable columns given this subsampling\n",
    "                keep = []\n",
    "                seqsamp[seqsamp == \"-\"] = \"N\"\n",
    "                rmcol = np.all(seqsamp == \"N\", axis=0)\n",
    "                seqsamp = seqsamp[:, ~rmcol]\n",
    "\n",
    "                ## write to a nexus file\n",
    "                matrix = dict(zip(hdict.keys(), [i.tostring() for i in seqsamp]))\n",
    "                nexmake(matrix, nloci, \"out\", name)\n",
    "    print nloci, 'loci kept'            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the loci for hypotheses H4 and H6\n",
    "Print the first and last locus, just for our edification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5573        CGGCGAGNTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D12950      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D13052      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D13063      ------------CTGCAAATCTGGTTTGGGGNGTTGCTGAATTTCTGCCNTNTGGGTNGTTG\n",
      "D13097      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D13103      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D13374      CGGCGRGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14269      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTGG\n",
      "D14477      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14478      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14480      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14482      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14483      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14485      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTKCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14504      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14505      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTKCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "D14506      CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTKCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF155       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF164       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF172       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF175       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF197       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF200       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF209       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGNTGCTGAATTTCTGCCNTCTGGGNAGTTG\n",
      "SF224       CGGCGAGTTTTACTGAAAATCTGGTTTGGGGTGTTTCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF228       CGGCGAGTTTTACTGMAAATCTGGTTTGGGGTGTTKCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF276       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF286       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF327       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "SF328       CGGCGAGTTTTACTGCAAATCTGGTTTGGGGTGTTGCTGAATTTCTGCCATCTGGGTAGTTG\n",
      "//               -         *                   *                        - |6\n",
      "D14269      TTCAGTCAACAAGTGTATTATTGTCCATCTAATGAAAAGGGTGATGGAGTTTAGCAATTA\n",
      "D14478      TTCAGTCAAMAAGTGTATTATTGTCCATCTAATGAAAAGGGTGATGGAGTTTAGCAATTA\n",
      "SF197       TWCRGTCAACAAGTGTATTATTGTCCATCTAATGAAAAGNGTGATGGAGTTTAGCAATTA\n",
      "SFC1988     TTCAGTCAACAAGTGTATTATTGTCCATCTAATGAAAAGGGTGATGGAGTTTAGCAATTA\n",
      "//           - -     -                                                  |425414|\n"
     ]
    }
   ],
   "source": [
    "inloci = \"/Users/Sarah/Dropbox/Canarium_GBS/ipyrad/canarium_test/CanEnd_outfiles/CanEnd.loci\"\n",
    "loci = open(inloci).read().strip().split(\"|\\n\")\n",
    "\n",
    "print loci[0]\n",
    "print loci[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3bc9f336036f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12345\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparseloci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'D4' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "parseloci(loci, D4, \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746 loci kept\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "parseloci(loci, D5, \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 loci kept\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "parseloci(loci, D6, \"6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit jobs to run in parallel across many cores\n",
    "We are submitting the nexus file to MrBayes 3.2.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a parallel client\n",
    "ipyclient = ipyparallel.Client()\n",
    "lbview = ipyclient.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## call function across all engines\n",
    "def mrbayes(infile):\n",
    "    import subprocess\n",
    "    cmd = \"mb {}\".format(infile)\n",
    "    subprocess.check_call(cmd, shell=True)\n",
    "    #stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 566/566 tasks finished after 4158 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## submit all nexus files to run mb\n",
    "allnex = glob.glob(\"/home/deren/Documents/Canarium/analysis_bucky/testlocs4/*.nex\")\n",
    "asyncs = []\n",
    "for nex in allnex:\n",
    "    asyncs.append(lbview.apply(mrbayes, nex))\n",
    "\n",
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 746/746 tasks finished after 6359 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## submit all nexus files to run mb\n",
    "allnex = glob.glob(\"/home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/*.nex\")\n",
    "for nex in allnex:\n",
    "    lbview.apply(mrbayes, nex)\n",
    "\n",
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 558/558 tasks finished after 3689 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## submit all nexus files to run mb\n",
    "allnex = glob.glob(\"/home/deren/Documents/Canarium/analysis_bucky/testlocs6/*.nex\")\n",
    "for nex in allnex:\n",
    "    lbview.apply(mrbayes, nex)\n",
    "\n",
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run mbsum to summarize posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbsum(nexdir, nloci):    \n",
    "    import subprocess\n",
    "    ## combine trees from the two replicate runs\n",
    "    for n in range(1, nloci+1):\n",
    "        cmd = \"mbsum -n 0 -o {}{}.in {}{}.nex.run1.t {}{}.nex.run2.t\"\\\n",
    "              .format(nexdir, n, nexdir, n, nexdir, n)\n",
    "        subprocess.check_call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run mbsum\n",
    "#mbsum(\"analysis_bucky/testlocs4/\", 566)\n",
    "mbsum(\"/home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/\", 746)\n",
    "#mbsum(\"analysis_bucky/testlocs6/\", 558)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run bucky to infer concordance factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bucky(arg):\n",
    "    import subprocess\n",
    "    subprocess.check_call(arg, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bucky -a 0.1 -k 4 -n 4000000 -c 4 -o /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/BUCKY.0.1 /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/*.in',\n",
       " 'bucky -a 1 -k 4 -n 4000000 -c 4 -o /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/BUCKY.1 /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/*.in',\n",
       " 'bucky -a 10 -k 4 -n 4000000 -c 4 -o /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/BUCKY.10 /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/*.in']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## enter args for each run\n",
    "args = []\n",
    "for insdir in [\"/home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/\"]:\n",
    "    ## alpha at three levels\n",
    "    for alpha in [0.1, 1, 10]:\n",
    "        args.append(\"bucky -a {} -k 4 -n 4000000 -c 4 -o {}/BUCKY.{} {}/*.in\".\\\n",
    "                    format(alpha, os.path.realpath(insdir), alpha, os.path.realpath(insdir)))\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bucky -a 0.1 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs4/BUCKY.0.1 /home/deren/Documents/Canarium/analysis_bucky/testlocs4/*.in',\n",
       " 'bucky -a 1 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs4/BUCKY.1 /home/deren/Documents/Canarium/analysis_bucky/testlocs4/*.in',\n",
       " 'bucky -a 10 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs4/BUCKY.10 /home/deren/Documents/Canarium/analysis_bucky/testlocs4/*.in',\n",
       " 'bucky -a 0.1 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs5/BUCKY.0.1 /home/deren/Documents/Canarium/analysis_bucky/testlocs5/*.in',\n",
       " 'bucky -a 1 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs5/BUCKY.1 /home/deren/Documents/Canarium/analysis_bucky/testlocs5/*.in',\n",
       " 'bucky -a 10 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs5/BUCKY.10 /home/deren/Documents/Canarium/analysis_bucky/testlocs5/*.in',\n",
       " 'bucky -a 0.1 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs6/BUCKY.0.1 /home/deren/Documents/Canarium/analysis_bucky/testlocs6/*.in',\n",
       " 'bucky -a 1 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs6/BUCKY.1 /home/deren/Documents/Canarium/analysis_bucky/testlocs6/*.in',\n",
       " 'bucky -a 10 -k 4 -n 4000000 -c 4 -o /home/deren/Documents/Canarium/analysis_bucky/testlocs6/BUCKY.10 /home/deren/Documents/Canarium/analysis_bucky/testlocs6/*.in']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## enter args for each run\n",
    "args = []\n",
    "for insdir in [\"./analysis_bucky/testlocs4\", \n",
    "               \"./analysis_bucky/testlocs5\", \n",
    "               \"./analysis_bucky/testlocs6\"]:\n",
    "    ## alpha at three levels\n",
    "    for alpha in [0.1, 1, 10]:\n",
    "        args.append(\"bucky -a {} -k 4 -n 4000000 -c 4 -o {}/BUCKY.{} {}/*.in\".\\\n",
    "                    format(alpha, os.path.realpath(insdir), alpha, os.path.realpath(insdir)))\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3/3 tasks finished after 26776 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## run on parallel processors\n",
    "for job in args:\n",
    "    async = lbview.apply(bucky, job)\n",
    "\n",
    "ipyclient.wait_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\r\n",
      " 1 K3,\r\n",
      " 2 K2,\r\n",
      " 3 K1,\r\n",
      " 4 out,\r\n",
      " 5 K4;\r\n",
      "\r\n",
      "Population Tree:\r\n",
      "((1,2),(3,4),5);\r\n",
      "\r\n",
      "Primary Concordance Tree Topology:\r\n",
      "((1,2),(3,4),5);\r\n",
      "\r\n",
      "Population Tree, With Branch Lengths In Estimated Coalescent Units:\r\n",
      "((1:10.000,2:10.000):0.543,(3:10.000,4:10.000):0.173,5:10.000);\r\n",
      "\r\n",
      "Primary Concordance Tree with Sample Concordance Factors:\r\n",
      "((1:1.000,2:1.000):0.553,(3:1.000,4:1.000):0.355,5:1.000);\r\n",
      "\r\n",
      "Four-way partitions in the Population Tree: sample-wide CF, coalescent units and Ties(if present)\r\n",
      "{1; 2|3,4; 5}\t0.613, 0.543,  \r\n",
      "{1,2; 5|3; 4}\t0.439, 0.173,  \r\n",
      "\r\n",
      "Splits in the Primary Concordance Tree: sample-wide and genome-wide mean CF (95% credibility), SD of mean sample-wide CF across runs\r\n",
      "{1,2|3,4,5} 0.553(0.502,0.606) 0.552(0.486,0.618)\t0.000\r\n",
      "{1,2,5|3,4} 0.355(0.307,0.403) 0.355(0.294,0.417)\t0.000\r\n",
      "\r\n",
      "Splits NOT in the Primary Concordance Tree but with estimated CF > 0.050:\r\n",
      "{1,2,4|3,5} 0.277(0.230,0.327) 0.277(0.218,0.339)\t0.000\r\n",
      "{1,5|2,3,4} 0.159(0.120,0.200) 0.159(0.112,0.211)\t0.000\r\n",
      "{1,4|2,3,5} 0.123(0.094,0.152) 0.123(0.085,0.164)\t0.000\r\n",
      "{1,3,5|2,4} 0.123(0.092,0.155) 0.123(0.083,0.167)\t0.000\r\n",
      "{1,2,3|4,5} 0.121(0.087,0.159) 0.121(0.079,0.169)\t0.000\r\n",
      "{1,3|2,4,5} 0.105(0.072,0.141) 0.105(0.065,0.151)\t0.000\r\n",
      "{1,4,5|2,3} 0.096(0.065,0.133) 0.097(0.058,0.141)\t0.000\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 35 analysis_bucky/testlocs4/BUCKY.1.concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: error reading ‘/home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/’: Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 35 /home/deren/Dropbox/Canarium_GBS/analysis_bucky/testlocs5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\r\n",
      " 1 K3,\r\n",
      " 2 K2,\r\n",
      " 3 K1,\r\n",
      " 4 K5,\r\n",
      " 5 K4,\r\n",
      " 6 out;\r\n",
      "\r\n",
      "Population Tree:\r\n",
      "(((1,2),(4,5)),3,6);\r\n",
      "\r\n",
      "Primary Concordance Tree Topology:\r\n",
      "(((1,2),(4,5)),3,6);\r\n",
      "\r\n",
      "Population Tree, With Branch Lengths In Estimated Coalescent Units:\r\n",
      "(((1:10.000,2:10.000):0.581,(4:10.000,5:10.000):0.659):0.429,3:10.000,6:10.000);\r\n",
      "\r\n",
      "Primary Concordance Tree with Sample Concordance Factors:\r\n",
      "(((1:1.000,2:1.000):0.466,(4:1.000,5:1.000):0.569):0.416,3:1.000,6:1.000);\r\n",
      "\r\n",
      "Four-way partitions in the Population Tree: sample-wide CF, coalescent units and Ties(if present)\r\n",
      "{1; 2|3,6; 4,5}\t0.627, 0.581,  \r\n",
      "{1,2; 4,5|3; 6}\t0.566, 0.429,  \r\n",
      "{1,2; 3,6|4; 5}\t0.655, 0.659,  \r\n",
      "\r\n",
      "Splits in the Primary Concordance Tree: sample-wide and genome-wide mean CF (95% credibility), SD of mean sample-wide CF across runs\r\n",
      "{1,2,3,6|4,5} 0.569(0.507,0.627) 0.568(0.492,0.642)\t0.000\r\n",
      "{1,2|3,4,5,6} 0.466(0.406,0.530) 0.466(0.391,0.543)\t0.001\r\n",
      "{1,2,4,5|3,6} 0.416(0.337,0.489) 0.415(0.327,0.500)\t0.001\r\n",
      "\r\n",
      "Splits NOT in the Primary Concordance Tree but with estimated CF > 0.050:\r\n",
      "{1,2,5,6|3,4} 0.168(0.114,0.209) 0.168(0.107,0.224)\t0.001\r\n",
      "{1,2,6|3,4,5} 0.112(0.062,0.176) 0.112(0.057,0.182)\t0.001\r\n",
      "{1,5|2,3,4,6} 0.109(0.072,0.141) 0.109(0.065,0.154)\t0.001\r\n",
      "{1,6|2,3,4,5} 0.106(0.072,0.153) 0.106(0.064,0.160)\t0.000\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 35 analysis_bucky/testlocs5/BUCKY.1.concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\r\n",
      " 1 K3,\r\n",
      " 2 K2,\r\n",
      " 3 K1,\r\n",
      " 4 K6,\r\n",
      " 5 K5,\r\n",
      " 6 K4,\r\n",
      " 7 out;\r\n",
      "\r\n",
      "Population Tree:\r\n",
      "((((1,6),2),(4,5)),3,7);\r\n",
      "\r\n",
      "Primary Concordance Tree Topology:\r\n",
      "((((1,6),2),(4,5)),3,7);\r\n",
      "\r\n",
      "Population Tree, With Branch Lengths In Estimated Coalescent Units:\r\n",
      "((((1:10.000,6:10.000):0.072,2:10.000):0.647,(4:10.000,5:10.000):0.797):0.309,3:10.000,7:10.000);\r\n",
      "\r\n",
      "Primary Concordance Tree with Sample Concordance Factors:\r\n",
      "((((1:1.000,6:1.000):0.261,2:1.000):0.455,(4:1.000,5:1.000):0.634):0.366,3:1.000,7:1.000);\r\n",
      "\r\n",
      "Four-way partitions in the Population Tree: sample-wide CF, coalescent units and Ties(if present)\r\n",
      "{1,2,6; 4,5|3; 7}\t0.510, 0.309,  \r\n",
      "{1,2,6; 3,7|4; 5}\t0.699, 0.797,  \r\n",
      "{1,6; 2|3,7; 4,5}\t0.651, 0.647,  \r\n",
      "{1; 6|2; 3,4,5,7}\t0.380, 0.072,  \r\n",
      "\r\n",
      "Splits in the Primary Concordance Tree: sample-wide and genome-wide mean CF (95% credibility), SD of mean sample-wide CF across runs\r\n",
      "{1,2,3,6,7|4,5} 0.634(0.566,0.699) 0.634(0.554,0.709)\t0.003\r\n",
      "{1,2,6|3,4,5,7} 0.455(0.362,0.539) 0.455(0.353,0.550)\t0.009\r\n",
      "{1,2,4,5,6|3,7} 0.366(0.287,0.457) 0.365(0.277,0.464)\t0.012\r\n",
      "{1,6|2,3,4,5,7} 0.261(0.185,0.341) 0.260(0.177,0.349)\t0.006\r\n",
      "\r\n",
      "Splits NOT in the Primary Concordance Tree but with estimated CF > 0.050:\r\n",
      "{1,2|3,4,5,6,7} 0.231(0.161,0.312) 0.231(0.154,0.319)\t0.005\r\n",
      "{1,3,4,5,7|2,6} 0.210(0.136,0.294) 0.210(0.129,0.301)\t0.003\r\n",
      "{1,2,6,7|3,4,5} 0.180(0.108,0.249) 0.180(0.103,0.258)\t0.011\r\n",
      "{1,3,4,5,6|2,7} 0.094(0.047,0.163) 0.094(0.042,0.168)\t0.007\r\n",
      "{1,2,5,6,7|3,4} 0.089(0.050,0.133) 0.089(0.046,0.141)\t0.001\r\n",
      "{1,2,3,4,7|5,6} 0.088(0.043,0.136) 0.088(0.040,0.144)\t0.000\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 40 analysis_bucky/testlocs6/BUCKY.1.concordance"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
