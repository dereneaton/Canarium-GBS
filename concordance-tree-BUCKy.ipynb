{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Canarium bucky analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## import Python libraries\n",
    "import ipyparallel as ipp\n",
    "import subprocess as sps\n",
    "import ipyrad as ip\n",
    "import glob\n",
    "import os\n",
    "import ipyrad.file_conversion as ifc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## conda install -c ipyrad bucky\n",
    "## conda install -c ipyrad ipyrad\n",
    "## conda install -c BioBuilds mrbayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 engines found\n"
     ]
    }
   ],
   "source": [
    "## look for running ipcluster instance, and create load-balancer\n",
    "ipyclient = ipp.Client()\n",
    "lbview = ipyclient.load_balanced_view()\n",
    "print \"{} engines found\".format(len(ipyclient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "## push imports to parallel engines\n",
    "import subprocess as sps\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/output organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## enter the data file for your analysis here\n",
    "LOCIFILE = \"/home/deren/Documents/Canarium/analysis-ipyrad/Canarium_min4_outfiles/Canarium_min4.loci\"\n",
    "WORKDIR = \"analysis-bucky\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infile is: /home/deren/Documents/Canarium/analysis-ipyrad/Canarium_min4_outfiles/Canarium_min4.loci\n",
      "outdir is: /home/deren/Documents/Canarium/analysis-bucky\n"
     ]
    }
   ],
   "source": [
    "## This ensures the file paths are Full Paths (not relative) \n",
    "LOCIFILE = os.path.realpath(LOCIFILE)\n",
    "assert os.path.exists(LOCIFILE)\n",
    "WORKDIR = os.path.realpath(WORKDIR)\n",
    "print \"infile is:\", LOCIFILE\n",
    "print \"outdir is:\", WORKDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## hypothesis for 4 species + outgroup\n",
    "D4 = [\"D14269\",\n",
    "      \"SF328\",\n",
    "      \"D12950\",\n",
    "      \"D14478\",\n",
    "      \"SF224\",\n",
    "     ]\n",
    "\n",
    "## hypothesis for 5 species + outgroup\n",
    "D5 = [\"D14269\",\n",
    "      \"SF328\",\n",
    "      \"D12950\",\n",
    "      \"D14478\",\n",
    "      \"SF224\", \n",
    "      \"D14483\",\n",
    "     ]\n",
    "\n",
    "## hypothesis for 6 species + outgroup\n",
    "D6 = [\"D14269\",\n",
    "      \"SF328\",\n",
    "      \"D14483\",\n",
    "      \"D14478\",\n",
    "      \"D14505\",\n",
    "      \"D12950\",\n",
    "      \"SF224\"\n",
    "     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 199 nexus files to /home/deren/Documents/Canarium/analysis-bucky/bucky-D4\n",
      "wrote 247 nexus files to /home/deren/Documents/Canarium/analysis-bucky/bucky-D5\n",
      "wrote 282 nexus files to /home/deren/Documents/Canarium/analysis-bucky/bucky-D6\n"
     ]
    }
   ],
   "source": [
    "## create nexus files for this data set\n",
    "ifc.loci2multinex(name=\"D4\", \n",
    "                  locifile=LOCIFILE, \n",
    "                  subsamples=D4, \n",
    "                  minSNPs=2, \n",
    "                  mcmc_burnin=1000000,\n",
    "                  mcmc_ngen=4000000,\n",
    "                  mcmc_sample_freq=4000,\n",
    "                  outdir=WORKDIR)\n",
    "\n",
    "ifc.loci2multinex(name=\"D5\", \n",
    "                  locifile=LOCIFILE, \n",
    "                  subsamples=D5, \n",
    "                  minSNPs=2, \n",
    "                  mcmc_burnin=1000000,\n",
    "                  mcmc_ngen=4000000,\n",
    "                  mcmc_sample_freq=4000,\n",
    "                  outdir=WORKDIR)\n",
    "\n",
    "ifc.loci2multinex(name=\"D6\", \n",
    "                  locifile=LOCIFILE, \n",
    "                  subsamples=D6, \n",
    "                  minSNPs=2, \n",
    "                  mcmc_burnin=1000000,\n",
    "                  mcmc_ngen=4000000,\n",
    "                  mcmc_sample_freq=4000,\n",
    "                  outdir=WORKDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example NEXUS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NEXUS\n",
      "begin data;\n",
      "dimensions ntax=7 nchar=73;\n",
      "format datatype=dna interleave=yes gap=- missing=N;\n",
      "matrix\n",
      "D14269  AAGCTTCCCAAAGGAAGGCATTTGATTGGCTCTCATGTCTCTTACGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "SF224   AAGCTTCCCAAGGGAAGGCATTTGATTGCCTCTCATGTCTCTTATGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "D12950  AAGCTTCCCAAGGGAAGGCATTTGATTGCCTCTCATGTCTCTTATGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "SF328   AAGCTTCCCAAAGGAAGGCATTTGATTGGCTCTCATGTCTCTTATGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "D14483  AAGCTTCCCAAAGGAAGGCATTTGATTGGCTCTCATGTCTCTTATGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "D14478  AAGCTTCCCAAAGGAAGGCATTTGATTGGCTCTCATGTCTCTTATGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "D14505  AAGCTTCCCAAAGGAAGGCATTTGATTGGCTCTCATGTCTCTTATGATATTGATGTTAGATTGGAAGGTGAAG\n",
      "\n",
      "    ;\n",
      "\n",
      "begin mrbayes;\n",
      "set autoclose=yes nowarn=yes;\n",
      "lset nst=6 rates=gamma;\n",
      "mcmc ngen=4000000 samplefreq=4000 printfreq=4000000;\n",
      "sump burnin=1000000;\n",
      "sumt burnin=1000000;\n",
      "end;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get RUNDIR relative to WORKDIR to ensure it is a Full Path\n",
    "RUNDIR4 = os.path.join(WORKDIR, \"bucky-{}\".format(\"D4\"))\n",
    "RUNDIR5 = os.path.join(WORKDIR, \"bucky-{}\".format(\"D5\"))\n",
    "RUNDIR6 = os.path.join(WORKDIR, \"bucky-{}\".format(\"D6\"))\n",
    "\n",
    "## print an example nexus file\n",
    "with open(os.path.join(RUNDIR6, \"1.nex\")) as nex:\n",
    "    print nex.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get all nexus files for each data set\n",
    "nexfiles4 = glob.glob(os.path.join(RUNDIR4, \"*.nex\"))\n",
    "nexfiles5 = glob.glob(os.path.join(RUNDIR5, \"*.nex\"))\n",
    "nexfiles6 = glob.glob(os.path.join(RUNDIR6, \"*.nex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Submit jobs to run in parallel across many cores\n",
    "We are submitting the nexus file to MrBayes 3.2.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrbayes(infile):\n",
    "    ## double check file path\n",
    "    infile = os.path.realpath(infile)\n",
    "    if not os.path.exists(infile):\n",
    "        raise Exception(\"infile not found; try using a fullpath\")\n",
    "        \n",
    "    ## call mrbayes\n",
    "    cmd = ['mb', infile]\n",
    "    proc = sps.Popen(cmd, stderr=sps.STDOUT, stdout=sps.PIPE)\n",
    "    stdout = proc.communicate()\n",
    "    \n",
    "    ## check for errors\n",
    "    if proc.returncode:\n",
    "        return stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbsum(dirs):\n",
    "    trees1 = glob.glob(os.path.join(dirs, \"*.run1.t\"))\n",
    "    trees2 = glob.glob(os.path.join(dirs, \"*.run2.t\"))\n",
    "    tidx = 0\n",
    "    for tidx in xrange(len(trees1)):\n",
    "        cmd = [\"mbsum\", \n",
    "               \"-n\", \"0\", \n",
    "               \"-o\", os.path.join(dirs, str(tidx))+\".in\", \n",
    "               trees1[tidx], \n",
    "               trees2[tidx]]\n",
    "        proc = sps.Popen(cmd, stderr=sps.STDOUT, stdout=sps.PIPE)\n",
    "        proc.communicate()\n",
    "    print \"summed {} trees in: {}\".format(tidx, dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bucky(outname, indir, alpha, nchains, nreps, niter):\n",
    "    ## check paths\n",
    "    if not os.path.exists(indir):\n",
    "        raise Exception(\"infiles not found; try using a fullpath\")\n",
    "    \n",
    "    ## call bucky \n",
    "    infiles = os.path.join(indir, \"*.in\")\n",
    "    cmd = [\"bucky\", \n",
    "           \"-a\", str(alpha),\n",
    "           \"-c\", str(nchains),\n",
    "           \"-k\", str(nreps),\n",
    "           \"-n\", str(int(niter)), \n",
    "           \"-o\", outname, \n",
    "           infiles]\n",
    "    \n",
    "    cmd = \" \".join(cmd)\n",
    "    proc = sps.Popen(cmd, stderr=sps.STDOUT, stdout=sps.PIPE, shell=True)\n",
    "    stdout = proc.communicate()\n",
    "    if proc.returncode:\n",
    "        return \" \".join(cmd), stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run mrbayes on all nexus file in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## send jobs to the parallel engines\n",
    "asyncs = []\n",
    "for nexfile in nexfiles4 + nexfiles5 + nexfiles6:\n",
    "    async = lbview.apply(mrbayes, nexfile)\n",
    "    asyncs.append(async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress of mrbayes runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrbayes batch runs:\n",
      "728 jobs submitted\n",
      "728 jobs finished\n"
     ]
    }
   ],
   "source": [
    "ready =  [i for i in asyncs if i.ready()]\n",
    "failed = [i for i in ready if not i.successful()]\n",
    "\n",
    "## print progress\n",
    "print \"mrbayes batch runs:\"\n",
    "print \"{} jobs submitted\".format(len(asyncs))\n",
    "print \"{} jobs finished\".format(len(ready))\n",
    "\n",
    "## print errors, if any.\n",
    "if any(failed):\n",
    "    print failed[0].exception()\n",
    "    print failes[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## block progress until all mrbayes jobs are finished\n",
    "ipyclient.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run mbsum to summarize posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed 198 trees in: /home/deren/Documents/Canarium/analysis-bucky/bucky-D4\n",
      "summed 246 trees in: /home/deren/Documents/Canarium/analysis-bucky/bucky-D5\n",
      "summed 281 trees in: /home/deren/Documents/Canarium/analysis-bucky/bucky-D6\n"
     ]
    }
   ],
   "source": [
    "## run mbsum on each directory of tree files\n",
    "mbsum(RUNDIR4)\n",
    "mbsum(RUNDIR5)\n",
    "mbsum(RUNDIR6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Run bucky to infer concordance factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nchains = 4\n",
    "nreps = 4\n",
    "niter = 1e6\n",
    "alphas = [0.1, 1, 10]\n",
    "\n",
    "## submit jobs to run at several values of alpha\n",
    "bsyncs = []\n",
    "for rundir in [RUNDIR4, RUNDIR5, RUNDIR6]:\n",
    "    for alpha in alphas:\n",
    "        outname = os.path.join(rundir, \"bucky-{}\".format(alpha))\n",
    "        args = (outname, rundir, alpha, nchains, nreps, niter)\n",
    "        async = lbview.apply(bucky, *args)\n",
    "        bsyncs.append(async)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress of Bucky runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucky batch runs:\n",
      "9 jobs submitted\n",
      "9 jobs finished\n"
     ]
    }
   ],
   "source": [
    "ready =  [i for i in bsyncs if i.ready()]\n",
    "failed = [i for i in ready if not i.successful()]\n",
    "print \"bucky batch runs:\"\n",
    "print \"{} jobs submitted\".format(len(bsyncs))\n",
    "print \"{} jobs finished\".format(len(ready))\n",
    "if len(ready) == len(bsyncs):\n",
    "    ## print errors, if any.\n",
    "    if any(failed):\n",
    "        print failed[0].exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipyclient.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### View results\n",
    "alpha=1 results are below, the rest are in the github repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\r\n",
      " 1 D14269,\r\n",
      " 2 D12950,\r\n",
      " 3 SF224,\r\n",
      " 4 SF328,\r\n",
      " 5 D14478;\r\n",
      "\r\n",
      "Population Tree:\r\n",
      "((1,4),(2,3),5);\r\n",
      "\r\n",
      "Primary Concordance Tree Topology:\r\n",
      "((1,4),(2,3),5);\r\n",
      "\r\n",
      "Population Tree, With Branch Lengths In Estimated Coalescent Units:\r\n",
      "((1:10.000,4:10.000):0.733,(2:10.000,3:10.000):1.765,5:10.000);\r\n",
      "\r\n",
      "Primary Concordance Tree with Sample Concordance Factors:\r\n",
      "((1:1.000,4:1.000):0.656,(2:1.000,3:1.000):0.847,5:1.000);\r\n",
      "\r\n",
      "Four-way partitions in the Population Tree: sample-wide CF, coalescent units and Ties(if present)\r\n",
      "{1; 4|2,3; 5}\t0.680, 0.733,  \r\n",
      "{1,4; 5|2; 3}\t0.886, 1.765,  \r\n",
      "\r\n",
      "Splits in the Primary Concordance Tree: sample-wide and genome-wide mean CF (95% credibility), SD of mean sample-wide CF across runs\r\n",
      "{1,4,5|2,3} 0.847(0.774,0.905) 0.844(0.754,0.918)\t0.000\r\n",
      "{1,4|2,3,5} 0.656(0.568,0.744) 0.653(0.542,0.760)\t0.000\r\n",
      "\r\n",
      "Splits NOT in the Primary Concordance Tree but with estimated CF > 0.050:\r\n",
      "{1,2,3|4,5} 0.197(0.111,0.281) 0.197(0.100,0.302)\t0.000\r\n",
      "{1,2,5|3,4} 0.119(0.065,0.176) 0.120(0.054,0.196)\t0.000\r\n",
      "{1,5|2,3,4} 0.081(0.000,0.151) 0.081(0.000,0.169)\t0.000\r\n",
      "\r\n",
      "Average SD of mean sample-wide CF: 0.000\r\n",
      "\r\n",
      "All Splits:\r\n",
      "{1,4,5|2,3}\r\n",
      "#Genes      count in run(s) 1 through 4, Overall probability, Overall cumulative probability\r\n",
      "   124          1          0          1          0     0.000000    0.000000\r\n",
      "   125          1          0          1          1     0.000001    0.000001\r\n",
      "   126          4          0          0          0     0.000001    0.000002\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 40 analysis-bucky/bucky-D4/bucky-1.concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\r\n",
      " 1 D14269,\r\n",
      " 2 SF224,\r\n",
      " 3 D12950,\r\n",
      " 4 SF328,\r\n",
      " 5 D14483,\r\n",
      " 6 D14478;\r\n",
      "\r\n",
      "Population Tree:\r\n",
      "(((1,4),(2,3)),5,6);\r\n",
      "\r\n",
      "Primary Concordance Tree Topology:\r\n",
      "(((1,4),(2,3)),5,6);\r\n",
      "\r\n",
      "Population Tree, With Branch Lengths In Estimated Coalescent Units:\r\n",
      "(((1:10.000,4:10.000):1.172,(2:10.000,3:10.000):2.642):2.025,5:10.000,6:10.000);\r\n",
      "\r\n",
      "Primary Concordance Tree with Sample Concordance Factors:\r\n",
      "(((1:1.000,4:1.000):0.777,(2:1.000,3:1.000):0.938):0.853,5:1.000,6:1.000);\r\n",
      "\r\n",
      "Four-way partitions in the Population Tree: sample-wide CF, coalescent units and Ties(if present)\r\n",
      "{1; 4|2,3; 5,6}\t0.793, 1.172,  \r\n",
      "{1,4; 5,6|2; 3}\t0.953, 2.642,  \r\n",
      "{1,4; 2,3|5; 6}\t0.912, 2.025,  \r\n",
      "\r\n",
      "Splits in the Primary Concordance Tree: sample-wide and genome-wide mean CF (95% credibility), SD of mean sample-wide CF across runs\r\n",
      "{1,4,5,6|2,3} 0.938(0.866,0.984) 0.934(0.853,0.985)\t0.002\r\n",
      "{1,2,3,4|5,6} 0.853(0.773,0.923) 0.850(0.758,0.929)\t0.002\r\n",
      "{1,4|2,3,5,6} 0.777(0.648,0.879) 0.774(0.633,0.886)\t0.005\r\n",
      "\r\n",
      "Splits NOT in the Primary Concordance Tree but with estimated CF > 0.050:\r\n",
      "{1,5,6|2,3,4} 0.105(0.040,0.194) 0.105(0.033,0.204)\t0.002\r\n",
      "{1,5|2,3,4,6} 0.097(0.032,0.158) 0.097(0.028,0.172)\t0.002\r\n",
      "{1,2,3|4,5,6} 0.068(0.000,0.194) 0.068(0.000,0.204)\t0.004\r\n",
      "\r\n",
      "Average SD of mean sample-wide CF: 0.003\r\n",
      "\r\n",
      "All Splits:\r\n",
      "{1,4,5,6|2,3}\r\n",
      "#Genes      count in run(s) 1 through 4, Overall probability, Overall cumulative probability\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 40 analysis-bucky/bucky-D5/bucky-1.concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translate\r\n",
      " 1 D14269,\r\n",
      " 2 SF224,\r\n",
      " 3 D12950,\r\n",
      " 4 SF328,\r\n",
      " 5 D14483,\r\n",
      " 6 D14478,\r\n",
      " 7 D14505;\r\n",
      "\r\n",
      "Population Tree:\r\n",
      "((((1,4),(2,3)),5),6,7);\r\n",
      "\r\n",
      "Primary Concordance Tree Topology:\r\n",
      "((((1,4),(2,3)),5),6,7);\r\n",
      "\r\n",
      "Population Tree, With Branch Lengths In Estimated Coalescent Units:\r\n",
      "((((1:10.000,4:10.000):0.607,(2:10.000,3:10.000):2.113):2.091,5:10.000):0.170,6:10.000,7:10.000);\r\n",
      "\r\n",
      "Primary Concordance Tree with Sample Concordance Factors:\r\n",
      "((((1:1.000,4:1.000):0.612,(2:1.000,3:1.000):0.887):0.857,5:1.000):0.415,6:1.000,7:1.000);\r\n",
      "\r\n",
      "Four-way partitions in the Population Tree: sample-wide CF, coalescent units and Ties(if present)\r\n",
      "{1,2,3,4; 5|6; 7}\t0.438, 0.170,  \r\n",
      "{1; 4|2,3; 5,6,7}\t0.637, 0.607,  \r\n",
      "{1,4; 5,6,7|2; 3}\t0.919, 2.113,  \r\n",
      "{1,4; 2,3|5; 6,7}\t0.918, 2.091,  \r\n",
      "\r\n",
      "Splits in the Primary Concordance Tree: sample-wide and genome-wide mean CF (95% credibility), SD of mean sample-wide CF across runs\r\n",
      "{1,4,5,6,7|2,3} 0.887(0.830,0.936) 0.884(0.811,0.943)\t0.006\r\n",
      "{1,2,3,4|5,6,7} 0.857(0.777,0.922) 0.854(0.761,0.928)\t0.007\r\n",
      "{1,4|2,3,5,6,7} 0.612(0.482,0.706) 0.610(0.471,0.719)\t0.015\r\n",
      "{1,2,3,4,5|6,7} 0.415(0.298,0.543) 0.414(0.284,0.554)\t0.014\r\n",
      "\r\n",
      "Splits NOT in the Primary Concordance Tree but with estimated CF > 0.050:\r\n",
      "{1,2,3,4,6|5,7} 0.268(0.135,0.401) 0.267(0.127,0.410)\t0.018\r\n",
      "{1,2,3,4,7|5,6} 0.240(0.160,0.330) 0.239(0.148,0.342)\t0.003\r\n",
      "{1,2,3|4,5,6,7} 0.219(0.138,0.298) 0.218(0.127,0.314)\t0.003\r\n",
      "{1,5,6,7|2,3,4} 0.078(0.000,0.191) 0.078(0.000,0.197)\t0.011\r\n",
      "\r\n",
      "Average SD of mean sample-wide CF: 0.010\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 40 analysis-bucky/bucky-D6/bucky-1.concordance"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
