{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species delimitation in Malagasy Canarium using iBPP\n",
    "\n",
    "This notebook is an empirical application of ibpp for species delimitation using GBS data assembled in ipyrad. We use the ipyrad utility function to `loci2bpp` to programatticaly setup a range of tests and to deploy them in parallel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about this notebook\n",
    "This is a jupyter notebook. All code in this notebook is Python. You should be able to download and execute this notebook and reproduce all of our results. This notebook along with other notebooks and data files are hosted on github: https://github.com/sarahfederman/Canarium-GBS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyrad v.0.5.10\n"
     ]
    }
   ],
   "source": [
    "import ipyrad as ip\n",
    "import ipyparallel as ipp\n",
    "import pandas as pd\n",
    "import random\n",
    "import socket\n",
    "import ete3\n",
    "import sys\n",
    "import os\n",
    "\n",
    "## print versions\n",
    "print \"ipyrad v.{}\".format(ip.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory to store results files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WDIR = \"./analysis_bpp\"\n",
    "if not os.path.exists(WDIR):\n",
    "    os.mkdir(WDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup an ipyparallel cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute node: [4 cores] on oud\n"
     ]
    }
   ],
   "source": [
    "rc = ipp.Client()\n",
    "lbview = rc.load_balanced_view()\n",
    "\n",
    "## print some information about our cluster\n",
    "info = rc[:].apply(socket.gethostname)\n",
    "for host in set(info.result_dict.values()):\n",
    "    print \"compute node: [{} cores] on {}\".format(info.result_dict.values().count(host), host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## downoad .loci file from (replace dropbox link with zenodo link) and save path\n",
    "#! curl -LkO https://dl.dropboxusercontent.com/u/2538935/CanEnd_min20.loci\n",
    "LOCI = \"./CanEnd_min20.loci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            /-D\n",
      "         /-|\n",
      "      /-|   \\-C\n",
      "     |  |\n",
      "   /-|   \\-B\n",
      "  |  |\n",
      "  |  |   /-E\n",
      "--|   \\-|\n",
      "  |      \\-F\n",
      "  |\n",
      "   \\-A\n"
     ]
    }
   ],
   "source": [
    "## make a mapping dictionary grouping samples into 'species'\n",
    "IMAP6 = {\n",
    "    \"A\": ['SF172', 'SF175', 'SF328', 'SF200', 'SF209', 'D14528', 'SF276', 'SF286', 'D13052'],\n",
    "    \"B\": ['D13101', 'D13103', 'D14482', 'D14483'],\n",
    "    \"C\": ['D14504', 'D14505', 'D14506'],\n",
    "    \"D\": ['D14477', 'D14478', 'D14480', 'D14485', 'D14501', 'D14513'], \n",
    "    \"E\": ['D13090', 'D12950'],\n",
    "    \"F\": ['D13097', 'SF155', 'D13063', 'D12963', 'SF160', 'SF327',\n",
    "          'SF224', 'SF228', '5573', 'SF153', 'SF164', 'D13075', 'SF197'], \n",
    "    }\n",
    "\n",
    "\n",
    "## make a dictionary with min values to filter loci to those with N samples per species.\n",
    "MINMAP6 = {\n",
    "    \"A\": 8, \n",
    "    \"B\": 4, \n",
    "    \"C\": 3,\n",
    "    \"D\": 4, \n",
    "    \"E\": 2, \n",
    "    \"F\": 8,\n",
    "}\n",
    "\n",
    "\n",
    "## Species tree hypothesis ('guide tree') based on raxml & bucky results\n",
    "TREE6 = \"((((D,C),B),(E,F)),A);\"\n",
    "print ete3.Tree(TREE6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            /-D\n",
      "         /-|\n",
      "      /-|   \\-C\n",
      "     |  |\n",
      "   /-|   \\-B\n",
      "  |  |\n",
      "--|   \\-E\n",
      "  |\n",
      "   \\-A\n"
     ]
    }
   ],
   "source": [
    "## make a mapping dictionary grouping samples into 'species'\n",
    "IMAP5 = {\n",
    "    \"A\": ['SF172', 'SF175', 'SF328', 'SF200', 'SF209', 'D14528', 'SF276', 'SF286', 'D13052'],\n",
    "    \"B\": ['D13101', 'D13103', 'D14482', 'D14483'],\n",
    "    \"C\": ['D14504', 'D14505', 'D14506'],\n",
    "    \"D\": ['D14477', 'D14478', 'D14480', 'D14485', 'D14501', 'D14513'], \n",
    "    \"E\": ['D13090', 'D12950', 'D13097', 'SF155', 'D13063', 'D12963', 'SF160', 'SF327',\n",
    "          'SF224', 'SF228', '5573', 'SF153', 'SF164', 'D13075', 'SF197'], \n",
    "    }\n",
    "\n",
    "\n",
    "## make a dictionary with min values to filter loci to those with N samples per species.\n",
    "MINMAP5 = {\n",
    "    \"A\": 8, \n",
    "    \"B\": 4, \n",
    "    \"C\": 3,\n",
    "    \"D\": 4, \n",
    "    \"E\": 8, \n",
    "}\n",
    "\n",
    "\n",
    "## Species tree hypothesis ('guide tree') based on raxml & bucky results\n",
    "TREE5 = \"((((D,C),B),E),A);\"\n",
    "print ete3.Tree(TREE5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         /-B\n",
      "      /-|\n",
      "   /-|   \\-C\n",
      "  |  |\n",
      "--|   \\-D\n",
      "  |\n",
      "   \\-A\n"
     ]
    }
   ],
   "source": [
    "## make a mapping dictionary grouping samples into 'species'\n",
    "IMAP4 = {\n",
    "    \"A\": ['SF172', 'SF175', 'SF328', 'SF200', 'SF209', 'D14528', 'SF276', 'SF286', 'D13052'],\n",
    "    \"B\": ['D13101', 'D13103', 'D14482', 'D14483'],\n",
    "    \"C\": ['D14504', 'D14505', 'D14506', 'D14477', 'D14478', 'D14480', 'D14485', 'D14501', 'D14513'], \n",
    "    \"D\": ['D13090', 'D12950', 'SF155', 'D12963',  'SF327', 'SF224', 'SF228', '5573', \n",
    "          'SF164', 'SF153', 'SF160', 'D13063', 'D13075', 'D13097', 'SF197'], \n",
    "    }\n",
    "\n",
    "## \n",
    "MINMAP4 = {\n",
    "    \"A\": 6,\n",
    "    \"B\": 4,\n",
    "    \"C\": 6,\n",
    "    \"D\": 6    \n",
    "}\n",
    "\n",
    "## fix tree, and print it \n",
    "TREE4 = \"(((B,C), D),A);\"\n",
    "print ete3.Tree(TREE4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leaf_tot</th>\n",
       "      <th>juga</th>\n",
       "      <th>leaf_juga_ratio</th>\n",
       "      <th>stip_dist</th>\n",
       "      <th>stip_scar_length</th>\n",
       "      <th>pet_length</th>\n",
       "      <th>petiole_stip_ratio</th>\n",
       "      <th>lateral_petiolules</th>\n",
       "      <th>basal_petiolule</th>\n",
       "      <th>termil_petiolule</th>\n",
       "      <th>...</th>\n",
       "      <th>lateral_lft_W</th>\n",
       "      <th>lateral_L_widest_point</th>\n",
       "      <th>ll_lw_ratio</th>\n",
       "      <th>ll_wp_ratio</th>\n",
       "      <th>termil_lft_L</th>\n",
       "      <th>termil_lft_W</th>\n",
       "      <th>termil_L_widest_point</th>\n",
       "      <th>tl_tw_ratio</th>\n",
       "      <th>tl_wp_ratio</th>\n",
       "      <th>X2o_vein_pairs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiv</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF175</th>\n",
       "      <td>371.77</td>\n",
       "      <td>4.67</td>\n",
       "      <td>79.49</td>\n",
       "      <td>21.38</td>\n",
       "      <td>2.30</td>\n",
       "      <td>59.43</td>\n",
       "      <td>2.91</td>\n",
       "      <td>19.45</td>\n",
       "      <td>8.98</td>\n",
       "      <td>45.31</td>\n",
       "      <td>...</td>\n",
       "      <td>36.79</td>\n",
       "      <td>55.04</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>85.59</td>\n",
       "      <td>40.27</td>\n",
       "      <td>45.99</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1.88</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF328</th>\n",
       "      <td>268.61</td>\n",
       "      <td>4.00</td>\n",
       "      <td>67.15</td>\n",
       "      <td>39.91</td>\n",
       "      <td>1.39</td>\n",
       "      <td>67.65</td>\n",
       "      <td>1.72</td>\n",
       "      <td>9.01</td>\n",
       "      <td>5.40</td>\n",
       "      <td>27.41</td>\n",
       "      <td>...</td>\n",
       "      <td>33.04</td>\n",
       "      <td>41.29</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.35</td>\n",
       "      <td>67.84</td>\n",
       "      <td>29.39</td>\n",
       "      <td>40.11</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.71</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF200</th>\n",
       "      <td>208.42</td>\n",
       "      <td>3.67</td>\n",
       "      <td>58.15</td>\n",
       "      <td>12.60</td>\n",
       "      <td>1.78</td>\n",
       "      <td>32.21</td>\n",
       "      <td>2.60</td>\n",
       "      <td>8.58</td>\n",
       "      <td>4.63</td>\n",
       "      <td>29.89</td>\n",
       "      <td>...</td>\n",
       "      <td>27.35</td>\n",
       "      <td>37.53</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.37</td>\n",
       "      <td>55.54</td>\n",
       "      <td>30.66</td>\n",
       "      <td>34.89</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.59</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF209</th>\n",
       "      <td>218.85</td>\n",
       "      <td>4.00</td>\n",
       "      <td>56.69</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2.04</td>\n",
       "      <td>42.98</td>\n",
       "      <td>3.46</td>\n",
       "      <td>8.62</td>\n",
       "      <td>4.94</td>\n",
       "      <td>17.66</td>\n",
       "      <td>...</td>\n",
       "      <td>30.80</td>\n",
       "      <td>35.68</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>61.20</td>\n",
       "      <td>30.43</td>\n",
       "      <td>30.80</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.01</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14528</th>\n",
       "      <td>264.57</td>\n",
       "      <td>4.00</td>\n",
       "      <td>66.14</td>\n",
       "      <td>10.85</td>\n",
       "      <td>2.99</td>\n",
       "      <td>53.21</td>\n",
       "      <td>4.90</td>\n",
       "      <td>12.23</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.79</td>\n",
       "      <td>...</td>\n",
       "      <td>33.91</td>\n",
       "      <td>53.94</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.61</td>\n",
       "      <td>79.49</td>\n",
       "      <td>35.67</td>\n",
       "      <td>49.57</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.60</td>\n",
       "      <td>10.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF276</th>\n",
       "      <td>283.45</td>\n",
       "      <td>3.00</td>\n",
       "      <td>94.48</td>\n",
       "      <td>21.84</td>\n",
       "      <td>2.64</td>\n",
       "      <td>74.72</td>\n",
       "      <td>3.55</td>\n",
       "      <td>12.56</td>\n",
       "      <td>8.35</td>\n",
       "      <td>31.82</td>\n",
       "      <td>...</td>\n",
       "      <td>37.79</td>\n",
       "      <td>52.69</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.31</td>\n",
       "      <td>82.05</td>\n",
       "      <td>44.05</td>\n",
       "      <td>51.32</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.60</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF286</th>\n",
       "      <td>288.35</td>\n",
       "      <td>3.00</td>\n",
       "      <td>96.12</td>\n",
       "      <td>27.57</td>\n",
       "      <td>2.75</td>\n",
       "      <td>72.73</td>\n",
       "      <td>2.65</td>\n",
       "      <td>17.31</td>\n",
       "      <td>11.73</td>\n",
       "      <td>35.23</td>\n",
       "      <td>...</td>\n",
       "      <td>52.27</td>\n",
       "      <td>42.52</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "      <td>83.78</td>\n",
       "      <td>46.91</td>\n",
       "      <td>44.01</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.93</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14504</th>\n",
       "      <td>323.02</td>\n",
       "      <td>6.00</td>\n",
       "      <td>54.21</td>\n",
       "      <td>12.54</td>\n",
       "      <td>2.82</td>\n",
       "      <td>65.82</td>\n",
       "      <td>6.09</td>\n",
       "      <td>8.60</td>\n",
       "      <td>5.32</td>\n",
       "      <td>18.30</td>\n",
       "      <td>...</td>\n",
       "      <td>48.74</td>\n",
       "      <td>44.06</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>70.46</td>\n",
       "      <td>36.71</td>\n",
       "      <td>34.97</td>\n",
       "      <td>1.94</td>\n",
       "      <td>2.05</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14505</th>\n",
       "      <td>448.82</td>\n",
       "      <td>8.00</td>\n",
       "      <td>56.25</td>\n",
       "      <td>9.51</td>\n",
       "      <td>3.00</td>\n",
       "      <td>63.97</td>\n",
       "      <td>6.70</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.67</td>\n",
       "      <td>23.10</td>\n",
       "      <td>...</td>\n",
       "      <td>54.47</td>\n",
       "      <td>45.00</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2.29</td>\n",
       "      <td>129.33</td>\n",
       "      <td>64.38</td>\n",
       "      <td>65.85</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.03</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14506</th>\n",
       "      <td>534.65</td>\n",
       "      <td>7.00</td>\n",
       "      <td>77.69</td>\n",
       "      <td>11.67</td>\n",
       "      <td>3.50</td>\n",
       "      <td>91.80</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.40</td>\n",
       "      <td>13.51</td>\n",
       "      <td>35.22</td>\n",
       "      <td>...</td>\n",
       "      <td>70.34</td>\n",
       "      <td>66.34</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.85</td>\n",
       "      <td>155.46</td>\n",
       "      <td>61.82</td>\n",
       "      <td>74.68</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.06</td>\n",
       "      <td>20.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        leaf_tot  juga  leaf_juga_ratio  stip_dist  stip_scar_length  \\\n",
       "Indiv                                                                  \n",
       "SF175     371.77  4.67            79.49      21.38              2.30   \n",
       "SF328     268.61  4.00            67.15      39.91              1.39   \n",
       "SF200     208.42  3.67            58.15      12.60              1.78   \n",
       "SF209     218.85  4.00            56.69      13.00              2.04   \n",
       "D14528    264.57  4.00            66.14      10.85              2.99   \n",
       "SF276     283.45  3.00            94.48      21.84              2.64   \n",
       "SF286     288.35  3.00            96.12      27.57              2.75   \n",
       "D14504    323.02  6.00            54.21      12.54              2.82   \n",
       "D14505    448.82  8.00            56.25       9.51              3.00   \n",
       "D14506    534.65  7.00            77.69      11.67              3.50   \n",
       "\n",
       "        pet_length  petiole_stip_ratio  lateral_petiolules  basal_petiolule  \\\n",
       "Indiv                                                                         \n",
       "SF175        59.43                2.91               19.45             8.98   \n",
       "SF328        67.65                1.72                9.01             5.40   \n",
       "SF200        32.21                2.60                8.58             4.63   \n",
       "SF209        42.98                3.46                8.62             4.94   \n",
       "D14528       53.21                4.90               12.23             9.12   \n",
       "SF276        74.72                3.55               12.56             8.35   \n",
       "SF286        72.73                2.65               17.31            11.73   \n",
       "D14504       65.82                6.09                8.60             5.32   \n",
       "D14505       63.97                6.70                5.77             5.67   \n",
       "D14506       91.80                8.00               15.40            13.51   \n",
       "\n",
       "        termil_petiolule       ...        lateral_lft_W  \\\n",
       "Indiv                          ...                        \n",
       "SF175              45.31       ...                36.79   \n",
       "SF328              27.41       ...                33.04   \n",
       "SF200              29.89       ...                27.35   \n",
       "SF209              17.66       ...                30.80   \n",
       "D14528             32.79       ...                33.91   \n",
       "SF276              31.82       ...                37.79   \n",
       "SF286              35.23       ...                52.27   \n",
       "D14504             18.30       ...                48.74   \n",
       "D14505             23.10       ...                54.47   \n",
       "D14506             35.22       ...                70.34   \n",
       "\n",
       "        lateral_L_widest_point  ll_lw_ratio  ll_wp_ratio  termil_lft_L  \\\n",
       "Indiv                                                                    \n",
       "SF175                    55.04         2.98         2.98         85.59   \n",
       "SF328                    41.29         2.35         2.35         67.84   \n",
       "SF200                    37.53         2.37         2.37         55.54   \n",
       "SF209                    35.68         2.05         2.05         61.20   \n",
       "D14528                   53.94         2.61         2.61         79.49   \n",
       "SF276                    52.69         2.31         2.31         82.05   \n",
       "SF286                    42.52         1.58         1.58         83.78   \n",
       "D14504                   44.06         1.70         1.70         70.46   \n",
       "D14505                   45.00         2.29         2.29        129.33   \n",
       "D14506                   66.34         2.85         2.85        155.46   \n",
       "\n",
       "        termil_lft_W  termil_L_widest_point  tl_tw_ratio  tl_wp_ratio  \\\n",
       "Indiv                                                                   \n",
       "SF175          40.27                  45.99         2.18         1.88   \n",
       "SF328          29.39                  40.11         2.32         1.71   \n",
       "SF200          30.66                  34.89         1.82         1.59   \n",
       "SF209          30.43                  30.80         2.03         2.01   \n",
       "D14528         35.67                  49.57         2.22         1.60   \n",
       "SF276          44.05                  51.32         1.87         1.60   \n",
       "SF286          46.91                  44.01         1.78         1.93   \n",
       "D14504         36.71                  34.97         1.94         2.05   \n",
       "D14505         64.38                  65.85         2.01         2.03   \n",
       "D14506         61.82                  74.68         2.52         2.06   \n",
       "\n",
       "        X2o_vein_pairs  \n",
       "Indiv                   \n",
       "SF175            10.67  \n",
       "SF328            10.50  \n",
       "SF200            10.00  \n",
       "SF209            10.67  \n",
       "D14528           10.33  \n",
       "SF276             8.00  \n",
       "SF286             8.50  \n",
       "D14504           16.67  \n",
       "D14505           17.50  \n",
       "D14506           20.33  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trait data (csv) from (https://zenodo.../CanEnd_trait2.csv\")\n",
    "TRAITS = pd.read_csv(\"./CanEnd_traits.csv\", na_values=\"\", index_col=0)\n",
    "TRAITS.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function to call bpp/ibpp\n",
    "We will submit a large range of jobs to our parallel cluster. First we will infer a species tree with bpp, and then we will add traits and test delimitation hypotheses with ibpp. To track the progress of all of the parallel processes we will store info about them (their async objects) in a dictionary called results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## a dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## a function to call i/bpp\n",
    "def bpp(ctlfile):\n",
    "    \"\"\" \n",
    "    This assumes you installed bpp & ibpp in ~/local/bin/ following the \n",
    "    installation instructions in the ipyrad bpp tutorial. \n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    import os\n",
    "    if \".ibpp\" in ctlfile:\n",
    "        cmd = [os.path.expanduser(\"~/local/bin/ibpp\"), ctlfile]\n",
    "    else:\n",
    "        cmd = [os.path.expanduser(\"~/local/bin/bpp\"), ctlfile]\n",
    "    subprocess.check_output(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer species tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new files created (1007 loci, 6 species, 37 samples)\n",
      "  tree-0.bpp.seq.txt\n",
      "  tree-0.bpp.imap.txt\n",
      "  tree-0.bpp.ctl.txt\n"
     ]
    }
   ],
   "source": [
    "## an initial test for the species tree from starting 'guide tree'\n",
    "ctl0 = ip.file_conversion.loci2bpp(\"tree-0\", LOCI, IMAP, TREE, \n",
    "                                   wdir=WDIR,\n",
    "                                   minmap=MINMAP,\n",
    "                                   infer_sptree=1,\n",
    "                                   infer_delimit=0,\n",
    "                                   maxloci=10000,  \n",
    "                                   nsample=100000,\n",
    "                                   burnin=10000,\n",
    "                                   sampfreq=2,\n",
    "                                   thetaprior=(2, 2000),\n",
    "                                   tauprior=(2, 200, 1)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer species delimitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ctl file\n",
      "--------\n",
      "seed = 545691\n",
      "seqfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-6sp-notraits-300L.bpp.seq.txt\n",
      "Imapfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-6sp-notraits-300L.bpp.imap.txt\n",
      "mcmcfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-6sp-notraits-300L.bpp.mcmc.txt\n",
      "outfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-6sp-notraits-300L.bpp.out.txt\n",
      "nloci = 300\n",
      "usedata = 1\n",
      "cleandata = 0\n",
      "speciestree = 0\n",
      "speciesdelimitation = 1 1 1 1\n",
      "species&tree = 6 A B C D E F\n",
      "                 9 4 3 6 2 13\n",
      "                 ((((D,C),B),(E,F)),A);\n",
      "thetaprior = 5 500\n",
      "tauprior = 20 200 1\n",
      "finetune = 1: 2.0 0.01 0.01 0.0001 0.01 0.1 0.1 0.1\n",
      "print = 1 0 0 0\n",
      "burnin = 1000\n",
      "sampfreq = 2\n",
      "nsample = 10000\n",
      "--------\n",
      "\n",
      "new files created (300 loci, 6 species, 37 samples)\n",
      "  delim-6sp-notraits-300L.bpp.seq.txt\n",
      "  delim-6sp-notraits-300L.bpp.imap.txt\n",
      "  delim-6sp-notraits-300L.bpp.ctl.txt\n"
     ]
    }
   ],
   "source": [
    "## an initial test for the species tree from starting 'guide tree'\n",
    "ctl1 = ip.file_conversion.loci2bpp(\"delim-6sp-notraits-300L\", \n",
    "                                   #traits_df=TRAITS,\n",
    "                                   locifile=LOCI, \n",
    "                                   imap=IMAP6, \n",
    "                                   guidetree=TREE6, \n",
    "                                   minmap=MINMAP6,\n",
    "                                   wdir=WDIR,\n",
    "                                   infer_sptree=0,\n",
    "                                   infer_delimit=1,\n",
    "                                   delimit_alg=(1, 1, 1),\n",
    "                                   maxloci=300,  \n",
    "                                   nsample=10000,\n",
    "                                   burnin=1000,\n",
    "                                   sampfreq=2,\n",
    "                                   thetaprior=(5, 500),\n",
    "                                   tauprior=(20, 200, 1),\n",
    "                                   finetune=(2.0, 0.01, 0.01, 0.0001, 0.01, 0.1, 0.1, 0.1),\n",
    "                                   seed=random.randint(1,1e6),\n",
    "                                   verbose=1,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ctl file\n",
      "--------\n",
      "seed = 12345\n",
      "seqfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-100.bpp.seq.txt\n",
      "Imapfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-100.bpp.imap.txt\n",
      "mcmcfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-100.bpp.mcmc.txt\n",
      "outfile = /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-100.bpp.out.txt\n",
      "nloci = 100\n",
      "usedata = 1\n",
      "cleandata = 0\n",
      "speciestree = 0\n",
      "speciesdelimitation = 1 1.5 1.5 1.0\n",
      "species&tree = 7 A C B E D G F\n",
      "                 9 3 4 2 6 7 6\n",
      "                 ((((D,B),C),(E(F,G))),A);\n",
      "thetaprior = 5 500\n",
      "tauprior = 2 20 1\n",
      "finetune = 1: .01 .01 .01 .01 .01 .01 .01 .01\n",
      "print = 1 0 0 0\n",
      "burnin = 1000\n",
      "sampfreq = 2\n",
      "nsample = 10000\n",
      "--------\n",
      "\n",
      "new files created (100 loci, 7 species, 37 samples)\n",
      "  delim-100.bpp.seq.txt\n",
      "  delim-100.bpp.imap.txt\n",
      "  delim-100.bpp.ctl.txt\n"
     ]
    }
   ],
   "source": [
    "## an initial test for the species tree from starting 'guide tree'\n",
    "ctl1 = ip.file_conversion.loci2bpp(\"delim-7sp-100\", LOCI, IMAP, TREE, \n",
    "                                   wdir=WDIR,\n",
    "                                   minmap=MINMAP,\n",
    "                                   #traits_df=TRAITS,\n",
    "                                   infer_sptree=0,\n",
    "                                   infer_delimit=1,\n",
    "                                   delimit_alg=(1.5, 1.5, 1.0),\n",
    "                                   maxloci=100,  \n",
    "                                   nsample=10000,\n",
    "                                   burnin=1000,\n",
    "                                   sampfreq=2,\n",
    "                                   thetaprior=(5, 500),\n",
    "                                   tauprior=(2, 20, 1),\n",
    "                                   verbose=1,\n",
    "                                   #kappa=0,\n",
    "                                   #nu=1\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp&p Version 3.3, November 2016\n",
      "\n",
      "Reading options from /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-0.bpp.ctl.txt..\n",
      "6 species:  A (9) C (3) B (4) E (2) D (6) F (13)\n",
      "((((D, B), C), (E, F)), A);\n",
      "\n",
      "pop by pop table showing node numbers in species tree\n",
      "\n",
      "                        1  2  3  4  5  6  7  8  9 10 11\n",
      "species  1 A            1  0  0  0  0  0  1  0  0  0  0\n",
      "species  2 C            0  1  0  0  0  0  1  1  1  0  0\n",
      "species  3 B            0  0  1  0  0  0  1  1  1  1  0\n",
      "species  4 E            0  0  0  1  0  0  1  1  0  0  1\n",
      "species  5 D            0  0  0  0  1  0  1  1  1  1  0\n",
      "species  6 F            0  0  0  0  0  1  1  1  0  0  1\n",
      "species  7 DBCEFA       0  0  0  0  0  0  1  0  0  0  0\n",
      "species  8 DBCEF        0  0  0  0  0  0  1  1  0  0  0\n",
      "species  9 DBC          0  0  0  0  0  0  1  1  1  0  0\n",
      "species 10 DB           0  0  0  0  0  0  1  1  1  1  0\n",
      "species 11 EF           0  0  0  0  0  0  1  1  0  0  1\n",
      "\n",
      "11 theta parameters (populations) in the order:\n",
      "  theta_1A theta_2C theta_3B theta_4E theta_5D theta_6F theta_7DBCEFA theta_8DBCEF theta_9DBC theta_10DB theta_11EF\n",
      "5 species divergence times in the order:\n",
      "  tau_7DBCEFA tau_8DBCEF tau_9DBC tau_10DB tau_11EF\n",
      "\n",
      "Reading Individual-Species map (Imap) from /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-0.bpp.imap.txt\n",
      "Individual -> Species map:  1 1 1 1 1 1 1 1 1 3 3 3 3 2 2 2 5 5 5 5 5 5 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      "# individuals = 37 read from Imap file\n",
      "\n",
      "Reading sequence data..  100 loci\n",
      "\n",
      "ns = 34  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus  1: 34 sequences (  9  3  4  2  5 11 )    61 sites     7 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus  2: 36 sequences (  9  3  4  2  6 12 )    61 sites     6 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 68\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          21 patterns at       68 /       68 sites (100.0%),  0:00\n",
      "locus  3: 35 sequences (  9  3  4  2  6 11 )    68 sites    18 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 71\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          21 patterns at       71 /       71 sites (100.0%),  0:00\n",
      "locus  4: 34 sequences (  9  3  4  2  6 10 )    71 sites    18 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus  5: 34 sequences (  9  3  4  2  5 11 )    60 sites     6 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           8 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus  6: 34 sequences (  9  3  4  2  6 10 )    63 sites     5 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 71\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          23 patterns at       71 /       71 sites (100.0%),  0:00\n",
      "locus  7: 34 sequences (  9  3  4  2  6 10 )    71 sites    20 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 71\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          18 patterns at       71 /       71 sites (100.0%),  0:00\n",
      "locus  8: 34 sequences (  9  3  4  2  6 10 )    71 sites    15 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 76\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          17 patterns at       76 /       76 sites (100.0%),  0:00\n",
      "locus  9: 36 sequences (  8  3  4  2  6 13 )    76 sites    14 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          15 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 10: 34 sequences (  9  3  4  2  4 12 )    63 sites    12 patterns, messy\n",
      "\n",
      "ns = 31  \tls = 64\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #31: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          12 patterns at       64 /       64 sites (100.0%),  0:00\n",
      "locus 11: 31 sequences (  8  3  4  2  4 10 )    64 sites     8 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 69\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          23 patterns at       69 /       69 sites (100.0%),  0:00\n",
      "locus 12: 36 sequences (  9  3  4  2  6 12 )    69 sites    20 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 94\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          26 patterns at       94 /       94 sites (100.0%),  0:00\n",
      "locus 13: 34 sequences (  9  3  4  2  6 10 )    94 sites    23 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 78\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          18 patterns at       78 /       78 sites (100.0%),  0:00\n",
      "locus 14: 33 sequences (  9  3  4  2  5 10 )    78 sites    15 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 65\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           8 patterns at       65 /       65 sites (100.0%),  0:00\n",
      "locus 15: 35 sequences (  9  3  4  2  5 12 )    65 sites     5 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus 16: 35 sequences (  9  3  4  2  6 11 )    61 sites     6 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 65\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       65 /       65 sites (100.0%),  0:00\n",
      "locus 17: 35 sequences (  9  3  4  2  6 11 )    65 sites     6 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 18: 37 sequences (  9  3  4  2  6 13 )    63 sites     1 patterns, clean\n",
      "\n",
      "ns = 36  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          13 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 19: 36 sequences (  9  3  4  2  6 12 )    63 sites    10 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 20: 37 sequences (  9  3  4  2  6 13 )    63 sites     1 patterns, clean\n",
      "\n",
      "ns = 35  \tls = 75\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          24 patterns at       75 /       75 sites (100.0%),  0:00\n",
      "locus 21: 35 sequences (  9  3  4  2  6 11 )    75 sites    21 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 57\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           6 patterns at       57 /       57 sites (100.0%),  0:00\n",
      "locus 22: 37 sequences (  9  3  4  2  6 13 )    57 sites     3 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 77\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF327     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          12 patterns at       77 /       77 sites (100.0%),  0:00\n",
      "locus 23: 36 sequences (  8  3  4  2  6 13 )    77 sites     9 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 73\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          20 patterns at       73 /       73 sites (100.0%),  0:00\n",
      "locus 24: 34 sequences (  9  3  4  2  5 11 )    73 sites    17 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 25: 35 sequences (  9  3  4  2  6 11 )    63 sites     1 patterns, clean\n",
      "\n",
      "ns = 36  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 26: 36 sequences (  9  3  4  2  6 12 )    63 sites     1 patterns, clean\n",
      "\n",
      "ns = 36  \tls = 75\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          22 patterns at       75 /       75 sites (100.0%),  0:00\n",
      "locus 27: 36 sequences (  9  3  4  2  6 12 )    75 sites    19 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 95\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          15 patterns at       95 /       95 sites (100.0%),  0:00\n",
      "locus 28: 36 sequences (  9  3  4  2  6 12 )    95 sites    12 patterns, messy\n",
      "\n",
      "ns = 31  \tls = 66\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #31: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       66 /       66 sites (100.0%),  0:00\n",
      "locus 29: 31 sequences (  8  3  4  2  4 10 )    66 sites     6 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 79\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       79 /       79 sites (100.0%),  0:00\n",
      "locus 30: 36 sequences (  9  3  4  2  6 12 )    79 sites     8 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 51\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           5 patterns at       51 /       51 sites (100.0%),  0:00\n",
      "locus 31: 33 sequences (  8  3  4  2  5 11 )    51 sites     2 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 70\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          22 patterns at       70 /       70 sites (100.0%),  0:00\n",
      "locus 32: 34 sequences (  9  3  4  2  5 11 )    70 sites    19 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 72\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       72 /       72 sites (100.0%),  0:00\n",
      "locus 33: 37 sequences (  9  3  4  2  6 13 )    72 sites     8 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 54\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           8 patterns at       54 /       54 sites (100.0%),  0:00\n",
      "locus 34: 36 sequences (  9  3  4  2  6 12 )    54 sites     5 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 72\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          24 patterns at       72 /       72 sites (100.0%),  0:00\n",
      "locus 35: 33 sequences (  9  3  4  2  4 11 )    72 sites    21 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 74\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          26 patterns at       74 /       74 sites (100.0%),  0:00\n",
      "locus 36: 35 sequences (  9  3  4  2  6 11 )    74 sites    23 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 47\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           6 patterns at       47 /       47 sites (100.0%),  0:00\n",
      "locus 37: 34 sequences (  9  3  4  2  5 11 )    47 sites     3 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 72\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          24 patterns at       72 /       72 sites (100.0%),  0:00\n",
      "locus 38: 34 sequences (  8  3  4  2  6 11 )    72 sites    21 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 80\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          22 patterns at       80 /       80 sites (100.0%),  0:00\n",
      "locus 39: 35 sequences (  9  3  4  2  6 11 )    80 sites    19 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 65\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           6 patterns at       65 /       65 sites (100.0%),  0:00\n",
      "locus 40: 37 sequences (  9  3  4  2  6 13 )    65 sites     3 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 62\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          14 patterns at       62 /       62 sites (100.0%),  0:00\n",
      "locus 41: 35 sequences (  9  3  4  2  5 12 )    62 sites    11 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          14 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 42: 34 sequences (  9  3  4  2  6 10 )    60 sites    11 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           7 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 43: 36 sequences (  9  3  4  2  6 12 )    60 sites     4 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 86\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          16 patterns at       86 /       86 sites (100.0%),  0:00\n",
      "locus 44: 35 sequences (  9  3  4  2  6 11 )    86 sites    13 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 53\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       53 /       53 sites (100.0%),  0:00\n",
      "locus 45: 34 sequences (  9  3  4  2  6 10 )    53 sites     6 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 54\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           7 patterns at       54 /       54 sites (100.0%),  0:00\n",
      "locus 46: 36 sequences (  9  3  4  2  6 12 )    54 sites     4 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 66\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       66 /       66 sites (100.0%),  0:00\n",
      "locus 47: 36 sequences (  8  3  4  2  6 13 )    66 sites     6 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 48: 35 sequences (  9  3  4  2  6 11 )    60 sites     7 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 72\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          17 patterns at       72 /       72 sites (100.0%),  0:00\n",
      "locus 49: 33 sequences (  8  3  4  2  6 10 )    72 sites    14 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 59\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       59 /       59 sites (100.0%),  0:00\n",
      "locus 50: 34 sequences (  9  3  4  2  6 10 )    59 sites     8 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 77\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          20 patterns at       77 /       77 sites (100.0%),  0:00\n",
      "locus 51: 34 sequences (  9  3  4  2  6 10 )    77 sites    17 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 76\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF327     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          21 patterns at       76 /       76 sites (100.0%),  0:00\n",
      "locus 52: 34 sequences (  8  3  4  2  6 11 )    76 sites    18 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 79\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          26 patterns at       79 /       79 sites (100.0%),  0:00\n",
      "locus 53: 35 sequences (  9  3  4  2  6 11 )    79 sites    23 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 45\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       45 /       45 sites (100.0%),  0:00\n",
      "locus 54: 33 sequences (  9  3  4  2  5 10 )    45 sites     7 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 88\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          13 patterns at       88 /       88 sites (100.0%),  0:00\n",
      "locus 55: 37 sequences (  9  3  4  2  6 13 )    88 sites    10 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 69\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          14 patterns at       69 /       69 sites (100.0%),  0:00\n",
      "locus 56: 33 sequences (  8  3  4  2  5 11 )    69 sites    11 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 72\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          21 patterns at       72 /       72 sites (100.0%),  0:00\n",
      "locus 57: 34 sequences (  9  3  4  2  5 11 )    72 sites    18 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 58: 34 sequences (  9  3  4  2  6 10 )    63 sites     7 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 82\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          25 patterns at       82 /       82 sites (100.0%),  0:00\n",
      "locus 59: 36 sequences (  9  3  4  2  6 12 )    82 sites    22 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 81\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          19 patterns at       81 /       81 sites (100.0%),  0:00\n",
      "locus 60: 36 sequences (  9  3  4  2  6 12 )    81 sites    16 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 72\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          21 patterns at       72 /       72 sites (100.0%),  0:00\n",
      "locus 61: 35 sequences (  9  3  4  2  6 11 )    72 sites    18 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 83\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          21 patterns at       83 /       83 sites (100.0%),  0:00\n",
      "locus 62: 34 sequences (  9  3  4  2  6 10 )    83 sites    18 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF327     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           6 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus 63: 34 sequences (  8  3  4  2  6 11 )    61 sites     3 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 63\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           6 patterns at       63 /       63 sites (100.0%),  0:00\n",
      "locus 64: 35 sequences (  9  3  4  2  6 11 )    63 sites     3 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus 65: 36 sequences (  9  3  4  2  6 12 )    61 sites     1 patterns, clean\n",
      "\n",
      "ns = 33  \tls = 74\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          23 patterns at       74 /       74 sites (100.0%),  0:00\n",
      "locus 66: 33 sequences (  9  3  4  2  5 10 )    74 sites    20 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 67: 34 sequences (  8  3  4  2  6 11 )    60 sites     8 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 54\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       54 /       54 sites (100.0%),  0:00\n",
      "locus 68: 34 sequences (  8  3  4  2  6 11 )    54 sites     7 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           7 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus 69: 36 sequences (  9  3  4  2  6 12 )    61 sites     4 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 56\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           6 patterns at       56 /       56 sites (100.0%),  0:00\n",
      "locus 70: 36 sequences (  9  3  4  2  6 12 )    56 sites     3 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 65\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       65 /       65 sites (100.0%),  0:00\n",
      "locus 71: 34 sequences (  9  3  4  2  6 10 )    65 sites     8 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 68\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          18 patterns at       68 /       68 sites (100.0%),  0:00\n",
      "locus 72: 36 sequences (  9  3  4  2  6 12 )    68 sites    15 patterns, messy\n",
      "\n",
      "ns = 31  \tls = 57\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #31: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           8 patterns at       57 /       57 sites (100.0%),  0:00\n",
      "locus 73: 31 sequences (  8  3  4  2  4 10 )    57 sites     5 patterns, messy\n",
      "\n",
      "ns = 32  \tls = 62\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #32: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       62 /       62 sites (100.0%),  0:00\n",
      "locus 74: 32 sequences (  8  3  4  2  5 10 )    62 sites     1 patterns, clean\n",
      "\n",
      "ns = 33  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          12 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus 75: 33 sequences (  9  3  4  2  5 10 )    61 sites     9 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 78\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          19 patterns at       78 /       78 sites (100.0%),  0:00\n",
      "locus 76: 37 sequences (  9  3  4  2  6 13 )    78 sites    16 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           4 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 77: 37 sequences (  9  3  4  2  6 13 )    60 sites     1 patterns, clean\n",
      "\n",
      "ns = 35  \tls = 78\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          20 patterns at       78 /       78 sites (100.0%),  0:00\n",
      "locus 78: 35 sequences (  9  3  4  2  6 11 )    78 sites    17 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 56\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       56 /       56 sites (100.0%),  0:00\n",
      "locus 79: 33 sequences (  8  3  4  2  6 10 )    56 sites     8 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 57\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       57 /       57 sites (100.0%),  0:00\n",
      "locus 80: 34 sequences (  9  3  4  2  6 10 )    57 sites     6 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 56\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           7 patterns at       56 /       56 sites (100.0%),  0:00\n",
      "locus 81: 36 sequences (  9  3  4  2  6 12 )    56 sites     4 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 62\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       62 /       62 sites (100.0%),  0:00\n",
      "locus 82: 34 sequences (  9  3  4  2  6 10 )    62 sites     7 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 86\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          20 patterns at       86 /       86 sites (100.0%),  0:00\n",
      "locus 83: 34 sequences (  8  3  4  2  6 11 )    86 sites    17 patterns, messy\n",
      "\n",
      "ns = 37  \tls = 62\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #37: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       62 /       62 sites (100.0%),  0:00\n",
      "locus 84: 37 sequences (  9  3  4  2  6 13 )    62 sites     7 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 68\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          19 patterns at       68 /       68 sites (100.0%),  0:00\n",
      "locus 85: 33 sequences (  9  3  4  2  5 10 )    68 sites    16 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 87\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          19 patterns at       87 /       87 sites (100.0%),  0:00\n",
      "locus 86: 35 sequences (  9  3  4  2  6 11 )    87 sites    16 patterns, messy\n",
      "\n",
      "ns = 36  \tls = 61\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #36: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       61 /       61 sites (100.0%),  0:00\n",
      "locus 87: 36 sequences (  9  3  4  2  6 12 )    61 sites     8 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 65\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           8 patterns at       65 /       65 sites (100.0%),  0:00\n",
      "locus 88: 34 sequences (  9  3  4  2  5 11 )    65 sites     5 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 70\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          22 patterns at       70 /       70 sites (100.0%),  0:00\n",
      "locus 89: 34 sequences (  9  3  4  2  4 12 )    70 sites    19 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 67\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          12 patterns at       67 /       67 sites (100.0%),  0:00\n",
      "locus 90: 35 sequences (  9  3  4  2  6 11 )    67 sites     9 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 51\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       51 /       51 sites (100.0%),  0:00\n",
      "locus 91: 35 sequences (  9  3  4  2  4 13 )    51 sites     7 patterns, messy\n",
      "\n",
      "ns = 32  \tls = 84\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #32: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          25 patterns at       84 /       84 sites (100.0%),  0:00\n",
      "locus 92: 32 sequences (  8  3  4  2  5 10 )    84 sites    22 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 58\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          14 patterns at       58 /       58 sites (100.0%),  0:00\n",
      "locus 93: 35 sequences (  8  3  4  2  6 12 )    58 sites    11 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 55\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          10 patterns at       55 /       55 sites (100.0%),  0:00\n",
      "locus 94: 35 sequences (  9  3  4  2  6 11 )    55 sites     7 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 56\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       56 /       56 sites (100.0%),  0:00\n",
      "locus 95: 35 sequences (  9  3  4  2  6 11 )    56 sites     8 patterns, messy\n",
      "\n",
      "ns = 34  \tls = 56\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #34: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          11 patterns at       56 /       56 sites (100.0%),  0:00\n",
      "locus 96: 34 sequences (  8  3  4  2  6 11 )    56 sites     8 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 44\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "           9 patterns at       44 /       44 sites (100.0%),  0:00\n",
      "locus 97: 35 sequences (  9  3  4  2  6 11 )    44 sites     6 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          12 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 98: 35 sequences (  9  3  4  2  6 11 )    60 sites     9 patterns, messy\n",
      "\n",
      "ns = 33  \tls = 56\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #33: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          12 patterns at       56 /       56 sites (100.0%),  0:00\n",
      "locus 99: 33 sequences (  8  3  4  2  6 10 )    56 sites     9 patterns, messy\n",
      "\n",
      "ns = 35  \tls = 60\n",
      "Reading sequences, sequential format..\n",
      "Reading seq #35: ^SF328     \n",
      "Sequences read..\n",
      "Counting site patterns..  0:00\n",
      "          13 patterns at       60 /       60 sites (100.0%),  0:00\n",
      "locus 100: 35 sequences (  9  3  4  2  6 11 )    60 sites    10 patterns, messy\n",
      "2245696 bytes for conP, 492336 bytes for gene trees.  \n",
      "\n",
      "Number of species-delimitation models =  8\n",
      "\tdelimitation model   1: 00000  prior  0.12500\n",
      "\tdelimitation model   2: 10000  prior  0.12500\n",
      "\tdelimitation model   3: 11000  prior  0.12500\n",
      "\tdelimitation model   4: 11001  prior  0.12500\n",
      "\tdelimitation model   5: 11100  prior  0.12500\n",
      "\tdelimitation model   6: 11101  prior  0.12500\n",
      "\tdelimitation model   7: 11110  prior  0.12500\n",
      "\tdelimitation model   8: 11111  prior  0.12500\n",
      "\n",
      "[Note: Ancestral nodes in order:   7 DBCEFA  8 DBCEF  9 DBC 10 DB 11 EF]\n",
      "\n",
      "MCMC settings: 100 burnin, sampling every 2, 1000 samples\n",
      "Approximating posterior, using sequence data\n",
      "(Settings: cleandata=0 print=1 saveconP=1 moveinnode=1)\n",
      "\n",
      "Starting rjMCMC...\n",
      "PrSplit = 0.500000\n",
      "rj algorithm 0: new theta from sliding window with c = 5.00\n",
      "\n",
      "Starting species-delimitation model: 00000\n",
      "\n",
      "root dist = 0.00849\n",
      "\n",
      "Initial parameters, np = 1 (gene trees are generated from the prior):\n",
      "  0.00097\n",
      "lnL0 =  -12167.226\n",
      "  0% 0.70 0.02 0.00 0.00 0.65   1 0.0000 00000 P[1]=1.000  0.0014 0.0000 20485.04 -10601.8129  0:12\n",
      "  5% 0.70 0.02 0.00 0.00 0.79   1 0.0000 00000 P[1]=1.000  0.0020 0.0000 18724.49 -10129.8104  0:24\n",
      " 10% 0.70 0.03 0.00 0.00 0.81   1 0.0000 00000 P[1]=1.000  0.0024 0.0000 18976.77 -10105.4133  0:35\n",
      " 15% 0.70 0.03 0.00 0.00 0.85   1 0.0000 00000 P[1]=1.000  0.0026 0.0000 18846.91 -10094.8679  0:47\n",
      " 20% 0.70 0.04 0.00 0.00 0.87   1 0.0000 00000 P[1]=1.000  0.0026 0.0000 18971.62 -10089.1633  0:58\n",
      " 25% 0.70 0.04 0.00 0.00 0.88   1 0.0000 00000 P[1]=1.000  0.0027 0.0000 18547.67 -10086.1731  1:09\n",
      " 30% 0.70 0.04 0.01 0.00 0.89   1 0.0000 00000 P[1]=1.000  0.0028 0.0000 17525.56 -10083.6357  1:20\n",
      " 35% 0.70 0.04 0.01 0.00 0.90   1 0.0000 00000 P[1]=1.000  0.0029 0.0000 17956.26 -10081.7469  1:32\n",
      " 40% 0.70 0.04 0.01 0.00 0.90   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18444.04 -10081.4943  1:43\n",
      " 45% 0.70 0.04 0.01 0.00 0.90   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18522.85 -10081.8489  1:54\n",
      " 50% 0.70 0.04 0.01 0.00 0.89   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 17886.83 -10081.3982  2:05\n",
      " 55% 0.70 0.04 0.01 0.00 0.90   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18152.38 -10080.6011  2:18\n",
      " 60% 0.70 0.04 0.01 0.00 0.90   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18485.65 -10079.7730  2:30\n",
      " 65% 0.70 0.04 0.01 0.00 0.90   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18117.79 -10079.3977  2:43\n",
      " 70% 0.70 0.04 0.01 0.00 0.91   1 0.0000 00000 P[1]=1.000  0.0031 0.0000 18958.41 -10079.1022  2:55\n",
      " 75% 0.70 0.04 0.01 0.00 0.91   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18273.39 -10078.8130  3:07\n",
      " 80% 0.70 0.04 0.01 0.00 0.91   1 0.0000 00000 P[1]=1.000  0.0031 0.0000 18101.57 -10078.2119  3:18\n",
      " 85% 0.70 0.04 0.01 0.00 0.91   1 0.0000 00000 P[1]=1.000  0.0031 0.0000 18306.31 -10077.8142  3:29\n",
      " 90% 0.70 0.04 0.01 0.00 0.91   1 0.0000 00000 P[1]=1.000  0.0031 0.0000 18741.41 -10077.6532  3:40\n",
      " 95% 0.70 0.04 0.01 0.00 0.92   1 0.0000 00000 P[1]=1.000  0.0031 0.0000 18728.26 -10077.7612  3:52\n",
      "100% 0.70 0.04 0.01 0.00 0.92   1 0.0000 00000 P[1]=1.000  0.0030 0.0000 18649.72 -10078.0867  4:04\n",
      "\n",
      "Time used:  4:04\n",
      "\n",
      "Summarizing the species-delimitation sample in file /home/deren/Documents/Canarium-GBS/analysis_bpp/delim-0.bpp.mcmc.txt\n",
      "\n",
      "Number of species-delimitation models =  8\n",
      "      model    prior  posterior\n",
      "    1  00000   0.12500   1.00000\n",
      "    2  10000   0.12500   0.00000\n",
      "    3  11000   0.12500   0.00000\n",
      "    4  11001   0.12500   0.00000\n",
      "    5  11100   0.12500   0.00000\n",
      "    6  11101   0.12500   0.00000\n",
      "    7  11110   0.12500   0.00000\n",
      "    8  11111   0.12500   0.00000\n",
      "\n",
      "[Note: Ancestral nodes in order:   7 DBCEFA  8 DBCEF  9 DBC 10 DB 11 EF]\n",
      "\n",
      "Guide tree with posterior probability for presence of nodes\n",
      "((((D, B), C), (E, F)), A);\n"
     ]
    }
   ],
   "source": [
    "! bpp $ctl1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send job to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submitted /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0.bpp.ctl.txt\n",
      "submitted /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-0.ibpp.ctl.txt\n"
     ]
    }
   ],
   "source": [
    "## store async results in a dict\n",
    "asyncs = {}\n",
    "for ctl in [ctl0, ctl1]:\n",
    "    asyncs[ctl] = lbview.apply(bpp, ctl)\n",
    "    print \"submitted {}\".format(ctl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up many additional species delimitation tests\n",
    "We are interested in both how well the sequence data and the trait data can delimit species in Canarium. We will setup a range of tests to look at different settings for the priors, for different species delimitation algorithms, and for different types of data. We will start with a six taxon tree and allow the species delimitation algorithm to collapes nodes on the tree to test hypotheses of 1-6 species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set up a couple tests to perform\n",
    "DELIMIT_TESTS = [\n",
    "    (0, 2),\n",
    "    (0, 5),\n",
    "    (0, 10),\n",
    "    (1, 1.0, 1.0),\n",
    "    (1, 1.0, 1.5),\n",
    "    (1, 1.0, 2.0),\n",
    "    (1, 1.5, 1.0), \n",
    "    (1, 1.5, 1.5), \n",
    "    (1, 1.5, 2.0),\n",
    "    (1, 2.0, 1.0), \n",
    "    (1, 2.0, 1.5), \n",
    "    (1, 2.0, 2.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2b9df5859e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m## make input files and get ctl path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             ctl = ip.file_conversion.loci2bpp(rname, LOCI, imap, TREE, \n\u001b[0m\u001b[1;32m     15\u001b[0m                                           \u001b[0mminmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMINMAP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                           \u001b[0minfer_delimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imap' is not defined"
     ]
    }
   ],
   "source": [
    "## iterate over combinations for a total of 36 tests. \n",
    "## (1) 0/1 with or without traits \n",
    "## (2) 12 delimitation algorithm combinations (DELIMIT_TESTS)\n",
    "## (3) 3 independent replicates from different random seeds\n",
    "\n",
    "for usetraits in [0, 1]:\n",
    "    for tdx, delim in enumerate(DELIMIT_TESTS):\n",
    "        for rep in range(3):\n",
    "        \n",
    "            ## make a name for this test\n",
    "            rname = \"delim-{}-{}-{}\".format(usetraits, tdx, rep)\n",
    "        \n",
    "            ## make input files and get ctl path\n",
    "            ctl = ip.file_conversion.loci2bpp(rname, LOCI, IMAP, TREE, \n",
    "                                          minmap=MINMAP, \n",
    "                                          infer_delimit=1,\n",
    "                                          infer_sptree=0,\n",
    "                                          delimit_alg=delim,\n",
    "                                          traits=TRAITS,\n",
    "                                          maxloci=10000,  \n",
    "                                          nsample=100000,\n",
    "                                          burnin=10000,\n",
    "                                          sampfreq=2,\n",
    "                                          thetaprior=(2, 2000),\n",
    "                                          tauprior=(2, 200, 1),\n",
    "                                          usetraitdata=usetraits,\n",
    "                                          seed=random.randint(0, 1e9)\n",
    "                                          )\n",
    "        \n",
    "            ## send job to run on cluster\n",
    "            results[rname] = lbview.apply(bpp, ctl)\n",
    "            sys.stderr.write(\"job {} submitted\".format(rname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check success/failure of jobs\n",
    "for job in results:\n",
    "    ## get shorter name for job\n",
    "    jobname = job.split(\"/\")[-1]\n",
    "    \n",
    "    ## print done or not\n",
    "    if results[job].ready():\n",
    "        if results[job].successful():\n",
    "            print \"{:<30} -- finished\".format(jobname)\n",
    "        else:\n",
    "            print \"{:<30} -- failed:\".format(results[job].exception())\n",
    "    else:\n",
    "        print \"{:<30} -- still running\".format(jobname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse results (out.txt) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's read in the '.bpp.out.txt' results files for each test\n",
    "median_dict = {}\n",
    "ess_dict = {}\n",
    "\n",
    "for test, job in enumerate(sorted(asyncs)):\n",
    "    ## replace .ctl.txt with .out.txt\n",
    "    outname = job.replace(\".ctl.\", \".out.\")\n",
    "    \n",
    "    ## parse theta and tau priors from the job name\n",
    "    theta = job.split(\"-\")[1:3]\n",
    "    tau = job.split(\"-\")[3:5]\n",
    "    \n",
    "    ## read the file and parse out results\n",
    "    with open(outname, 'r') as infile:\n",
    "        data = infile.readlines()\n",
    "    \n",
    "    ## b/c sptree and delimit were set to 0 all this test did was infer sptree params\n",
    "    ## on the fixed tree. So let's compare the parameters under different priors\n",
    "    for line in data:\n",
    "        if \"theta_1\" and \"theta_2\" in line:\n",
    "            index = [\"theta mean\", \"tau mean\"] + line.split()\n",
    "            \n",
    "        if \"median\" in line:\n",
    "            data = [5./float(theta[1]), 1./float(tau[1])] + line.split()[1:]\n",
    "            median_dict[test] = pd.Series(data=data, index=index)\n",
    "            \n",
    "        if \"ESS*\" in line:\n",
    "            data = [5./float(theta[1]), 1./float(tau[1])] + line.split()[1:]\n",
    "            ess_dict[test] = pd.Series(data=data, index=index)\n",
    "\n",
    "## make results into a dataframe and print. It appears that the prior has a large effect on theta5 (AB)\n",
    "medians = pd.DataFrame(data=median_dict)\n",
    "ess = pd.DataFrame(data=ess_dict)\n",
    "\n",
    "## look at median values\n",
    "medians.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/2 tasks finished after 18258 s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-714fc16c6e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## check for finished jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/ysm-gpfs/home/de243/miniconda2/lib/python2.7/site-packages/ipyparallel/client/client.pyc\u001b[0m in \u001b[0;36mwait_interactive\u001b[0;34m(self, jobs, interval, timeout)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asyncresult_from_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;31m#--------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ysm-gpfs/home/de243/miniconda2/lib/python2.7/site-packages/ipyparallel/client/asyncresult.pyc\u001b[0m in \u001b[0;36mwait_interactive\u001b[0;34m(self, interval, timeout)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%4i/%i tasks finished after %4i s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ysm-gpfs/home/de243/miniconda2/lib/python2.7/site-packages/ipyparallel/client/asyncresult.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ysm-gpfs/home/de243/miniconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ysm-gpfs/home/de243/miniconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## check for finished jobs\n",
    "rc.wait_interactive()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
