{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species delimitation in Malagasy Canarium using iBPP\n",
    "\n",
    "This notebook is an empirical application of ibpp for species delimitation using GBS data assembled in ipyrad. We use the ipyrad utility function to `loci2bpp` to programatticaly setup a range of tests and to deploy them in parallel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about this notebook\n",
    "This is a jupyter notebook. All code in this notebook is Python. You should be able to download and execute this notebook and reproduce all of our results. This notebook along with other notebooks and data files are hosted on github: https://github.com/sarahfederman/Canarium-GBS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyrad v.0.5.13\n"
     ]
    }
   ],
   "source": [
    "import ipyrad as ip\n",
    "import ipyparallel as ipp\n",
    "import pandas as pd\n",
    "import random\n",
    "import socket\n",
    "import ete3\n",
    "import sys\n",
    "import os\n",
    "\n",
    "## print versions\n",
    "print \"ipyrad v.{}\".format(ip.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a directory to store results files in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WDIR = \"./analysis_bpp\"\n",
    "if not os.path.exists(WDIR):\n",
    "    os.mkdir(WDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup an ipyparallel cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host compute node: [20 cores] on c13n12.farnam.hpc.yale.internal\n"
     ]
    }
   ],
   "source": [
    "## open a view to the client\n",
    "ipyclient = ipp.Client()\n",
    "lbview = ipyclient.load_balanced_view()\n",
    "\n",
    "## confirm we are connected to 4 8-core nodes\n",
    "hosts = ipyclient[:].apply_sync(socket.gethostname)\n",
    "for hostname in set(hosts):\n",
    "    print(\"host compute node: [{} cores] on {}\"\\\n",
    "          .format(hosts.count(hostname), hostname))\n",
    "    \n",
    "#ipyclient.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## downoad .loci file from (replace dropbox link with zenodo link) and save path\n",
    "#! curl -LkO https://dl.dropboxusercontent.com/u/2538935/CanEnd_min20.loci\n",
    "LOCI = \"./CanEnd_min20.loci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            /-D\n",
      "         /-|\n",
      "      /-|   \\-C\n",
      "     |  |\n",
      "   /-|   \\-B\n",
      "  |  |\n",
      "  |  |   /-E\n",
      "--|   \\-|\n",
      "  |      \\-F\n",
      "  |\n",
      "   \\-A\n"
     ]
    }
   ],
   "source": [
    "## make a mapping dictionary grouping samples into 'species'\n",
    "IMAP6 = {\n",
    "    \"A\": ['SF172', 'SF175', 'SF328', 'SF200', 'SF209', 'D14528', 'SF276', 'SF286', 'D13052'],\n",
    "    \"B\": ['D13101', 'D13103', 'D14482', 'D14483'],\n",
    "    \"C\": ['D14504', 'D14505', 'D14506'],\n",
    "    \"D\": ['D14477', 'D14478', 'D14480', 'D14485', 'D14501', 'D14513'], \n",
    "    \"E\": ['D13090', 'D12950'],\n",
    "    \"F\": ['D13097', 'SF155', 'D13063', 'D12963', 'SF160', 'SF327',\n",
    "          'SF224', 'SF228', '5573', 'SF153', 'SF164', 'D13075', 'SF197'], \n",
    "    }\n",
    "\n",
    "\n",
    "## make a dictionary with min values to filter loci to those with N samples per species.\n",
    "MINMAP6 = {\n",
    "    \"A\": 8, \n",
    "    \"B\": 4, \n",
    "    \"C\": 3,\n",
    "    \"D\": 5, \n",
    "    \"E\": 2, \n",
    "    \"F\": 8,\n",
    "}\n",
    "\n",
    "\n",
    "## Species tree hypothesis ('guide tree') based on raxml & bucky results\n",
    "TREE6 = \"((((D,C),B),(E,F)),A);\"\n",
    "print ete3.Tree(TREE6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function to call bpp/ibpp\n",
    "We will submit a large range of jobs to our parallel cluster. First we will infer a species tree with bpp, and then we will add traits and test delimitation hypotheses with ibpp. To track the progress of all of the parallel processes we will store info about them (their async objects) in a dictionary called results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## a function to call i/bpp\n",
    "def bpp(ctlfile):\n",
    "    \"\"\" \n",
    "    This assumes you installed bpp & ibpp in ~/local/bin/ following the \n",
    "    installation instructions in the ipyrad bpp tutorial. \n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    import os\n",
    "    if \".ibpp\" in ctlfile:\n",
    "        cmd = [os.path.expanduser(\"~/local/bin/ibpp\"), ctlfile]\n",
    "    else:\n",
    "        cmd = [os.path.expanduser(\"~/local/bin/bpp\"), ctlfile]\n",
    "    subprocess.check_output(cmd)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer species tree \n",
    "We want to infer a species tree (infer_sptree=1; infer_delimit=0), however, to ensure adequate mixing of our mcmc analysis we'll run the analysis from 2 different starting trees, and from two different values for the prior theta. We also repeat each test starting from three different random seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-0-theta-200-tau-2000-rep-0.bpp.seq.txt\n",
      "  tree-0-theta-200-tau-2000-rep-0.bpp.imap.txt\n",
      "  tree-0-theta-200-tau-2000-rep-0.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-0-theta-200-tau-2000-rep-1.bpp.seq.txt\n",
      "  tree-0-theta-200-tau-2000-rep-1.bpp.imap.txt\n",
      "  tree-0-theta-200-tau-2000-rep-1.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-0-theta-200-tau-2000-rep-2.bpp.seq.txt\n",
      "  tree-0-theta-200-tau-2000-rep-2.bpp.imap.txt\n",
      "  tree-0-theta-200-tau-2000-rep-2.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-0-theta-2000-tau-2000-rep-0.bpp.seq.txt\n",
      "  tree-0-theta-2000-tau-2000-rep-0.bpp.imap.txt\n",
      "  tree-0-theta-2000-tau-2000-rep-0.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-0-theta-2000-tau-2000-rep-1.bpp.seq.txt\n",
      "  tree-0-theta-2000-tau-2000-rep-1.bpp.imap.txt\n",
      "  tree-0-theta-2000-tau-2000-rep-1.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-0-theta-2000-tau-2000-rep-2.bpp.seq.txt\n",
      "  tree-0-theta-2000-tau-2000-rep-2.bpp.imap.txt\n",
      "  tree-0-theta-2000-tau-2000-rep-2.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-1-theta-200-tau-2000-rep-0.bpp.seq.txt\n",
      "  tree-1-theta-200-tau-2000-rep-0.bpp.imap.txt\n",
      "  tree-1-theta-200-tau-2000-rep-0.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-1-theta-200-tau-2000-rep-1.bpp.seq.txt\n",
      "  tree-1-theta-200-tau-2000-rep-1.bpp.imap.txt\n",
      "  tree-1-theta-200-tau-2000-rep-1.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-1-theta-200-tau-2000-rep-2.bpp.seq.txt\n",
      "  tree-1-theta-200-tau-2000-rep-2.bpp.imap.txt\n",
      "  tree-1-theta-200-tau-2000-rep-2.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-1-theta-2000-tau-2000-rep-0.bpp.seq.txt\n",
      "  tree-1-theta-2000-tau-2000-rep-0.bpp.imap.txt\n",
      "  tree-1-theta-2000-tau-2000-rep-0.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-1-theta-2000-tau-2000-rep-1.bpp.seq.txt\n",
      "  tree-1-theta-2000-tau-2000-rep-1.bpp.imap.txt\n",
      "  tree-1-theta-2000-tau-2000-rep-1.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-1-theta-2000-tau-2000-rep-2.bpp.seq.txt\n",
      "  tree-1-theta-2000-tau-2000-rep-2.bpp.imap.txt\n",
      "  tree-1-theta-2000-tau-2000-rep-2.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-2-theta-200-tau-2000-rep-0.bpp.seq.txt\n",
      "  tree-2-theta-200-tau-2000-rep-0.bpp.imap.txt\n",
      "  tree-2-theta-200-tau-2000-rep-0.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-2-theta-200-tau-2000-rep-1.bpp.seq.txt\n",
      "  tree-2-theta-200-tau-2000-rep-1.bpp.imap.txt\n",
      "  tree-2-theta-200-tau-2000-rep-1.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-2-theta-200-tau-2000-rep-2.bpp.seq.txt\n",
      "  tree-2-theta-200-tau-2000-rep-2.bpp.imap.txt\n",
      "  tree-2-theta-200-tau-2000-rep-2.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-2-theta-2000-tau-2000-rep-0.bpp.seq.txt\n",
      "  tree-2-theta-2000-tau-2000-rep-0.bpp.imap.txt\n",
      "  tree-2-theta-2000-tau-2000-rep-0.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-2-theta-2000-tau-2000-rep-1.bpp.seq.txt\n",
      "  tree-2-theta-2000-tau-2000-rep-1.bpp.imap.txt\n",
      "  tree-2-theta-2000-tau-2000-rep-1.bpp.ctl.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  tree-2-theta-2000-tau-2000-rep-2.bpp.seq.txt\n",
      "  tree-2-theta-2000-tau-2000-rep-2.bpp.imap.txt\n",
      "  tree-2-theta-2000-tau-2000-rep-2.bpp.ctl.txt\n"
     ]
    }
   ],
   "source": [
    "TREES = [\"((((D,C),B),(E,F)),A);\", \n",
    "         \"((((D,B),C),(E,F)),A);\", \n",
    "         \"((((B,C),D),(E,F)),A);\"]\n",
    "\n",
    "## tree search for the best species tree. \n",
    "## Iterate over different starting trees.\n",
    "## Repeat x3 reps.\n",
    "ctls = []\n",
    "for tidx, tree in enumerate(TREES):\n",
    "    for theta in [200, 2000]:\n",
    "        for rep in range(3):\n",
    "            ## build input files\n",
    "            name = \"tree-{}-theta-{}-tau-2000-rep-{}\".format(tidx, theta, rep)\n",
    "            ctl = ip.file_conversion.loci2bpp(name, \n",
    "                                              locifile=LOCI,\n",
    "                                              imap=IMAP6,      \n",
    "                                              minmap=MINMAP6,\n",
    "                                              guidetree=tree,\n",
    "                                              wdir=WDIR,\n",
    "                                              infer_sptree=1,\n",
    "                                              infer_delimit=0,\n",
    "                                              maxloci=10000,\n",
    "                                              nsample=100000,\n",
    "                                              burnin=10000,\n",
    "                                              sampfreq=2,\n",
    "                                              thetaprior=(2, theta),\n",
    "                                              tauprior=(2, 2000, 1),\n",
    "                                              seed=random.randint(1,1e6),\n",
    "                                              finetune=(300.0, 0.0002, 0.0001, \n",
    "                                                        0.0001, 0.2, 1e-05, 0.1, 0.1),\n",
    "                                              )\n",
    "            ## store the ctl filename\n",
    "            ctls.append(ctl)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0-theta-200-tau-2000-rep-0.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0-theta-200-tau-2000-rep-1.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0-theta-200-tau-2000-rep-2.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0-theta-2000-tau-2000-rep-0.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0-theta-2000-tau-2000-rep-1.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-0-theta-2000-tau-2000-rep-2.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-1-theta-200-tau-2000-rep-0.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-1-theta-200-tau-2000-rep-1.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-1-theta-200-tau-2000-rep-2.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-1-theta-2000-tau-2000-rep-0.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-1-theta-2000-tau-2000-rep-1.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-1-theta-2000-tau-2000-rep-2.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-2-theta-200-tau-2000-rep-0.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-2-theta-200-tau-2000-rep-1.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-2-theta-200-tau-2000-rep-2.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-2-theta-2000-tau-2000-rep-0.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-2-theta-2000-tau-2000-rep-1.bpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/tree-2-theta-2000-tau-2000-rep-2.bpp.ctl.txt]\n"
     ]
    }
   ],
   "source": [
    "## a dictionary to store results\n",
    "tree_asyncs = {}\n",
    "\n",
    "## submit jobs to the cluster\n",
    "for job in ctls:\n",
    "    tree_asyncs[job] = lbview.apply(bpp, job)\n",
    "    sys.stderr.write(\"job submitted [{}]\\n\".format(job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  tree-1-theta-2000-tau-2000-rep-1.bpp.ctl.txt -- finished\n",
      "1  tree-1-theta-2000-tau-2000-rep-0.bpp.ctl.txt -- finished\n",
      "2  tree-2-theta-200-tau-2000-rep-2.bpp.ctl.txt -- finished\n",
      "3  tree-0-theta-200-tau-2000-rep-0.bpp.ctl.txt -- finished\n",
      "4  tree-2-theta-200-tau-2000-rep-0.bpp.ctl.txt -- finished\n",
      "5  tree-1-theta-200-tau-2000-rep-0.bpp.ctl.txt -- finished\n",
      "6  tree-1-theta-200-tau-2000-rep-2.bpp.ctl.txt -- finished\n",
      "7  tree-2-theta-2000-tau-2000-rep-2.bpp.ctl.txt -- finished\n",
      "8  tree-0-theta-200-tau-2000-rep-2.bpp.ctl.txt -- finished\n",
      "9  tree-2-theta-200-tau-2000-rep-1.bpp.ctl.txt -- finished\n",
      "10 tree-1-theta-2000-tau-2000-rep-2.bpp.ctl.txt -- finished\n",
      "11 tree-2-theta-2000-tau-2000-rep-0.bpp.ctl.txt -- finished\n",
      "12 tree-0-theta-200-tau-2000-rep-1.bpp.ctl.txt -- finished\n",
      "13 tree-1-theta-200-tau-2000-rep-1.bpp.ctl.txt -- finished\n",
      "14 tree-2-theta-2000-tau-2000-rep-1.bpp.ctl.txt -- finished\n",
      "15 tree-0-theta-2000-tau-2000-rep-0.bpp.ctl.txt -- finished\n",
      "16 tree-0-theta-2000-tau-2000-rep-1.bpp.ctl.txt -- finished\n",
      "17 tree-0-theta-2000-tau-2000-rep-2.bpp.ctl.txt -- finished\n"
     ]
    }
   ],
   "source": [
    "## check whether each has finished or failed\n",
    "for jid, job in enumerate(dict(tree_asyncs.items())):\n",
    "    ## get shorter name for job\n",
    "    jobname = job.split(\"/\")[-1]\n",
    "    \n",
    "    ## print done or not\n",
    "    if alljobs[job].ready():\n",
    "        if alljobs[job].successful():\n",
    "            print \"{:<3}{:<30} -- finished\".format(jid, jobname)\n",
    "        else:\n",
    "            print \"{:<3}{:<30} -- failed:\".format(jid, alljobs[job].exception())\n",
    "    else:\n",
    "        print \"{:<3}{:<30} -- still running\".format(jid, jobname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: mcmc[0]: command not found\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "mcmc = tree_asyncs.keys()\n",
    "mcmc = [i.replace(\".ctl.txt\", \".out.txt\") for i in mcmc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer species delimitation\n",
    "For species delimitation we'll start with our largest hypothesis based on clustering analysis, which is six species. This will test whether nodes on the six taxon tree should be collapsed into fewer. We use the topology supported in the species tree analysis above as our fixed species tree. We will run this analysis both with and without traits included, and test it over a range of starting values, and prior values. We performed initial runs to find good 'finetuning' parameters to maximize efficiency of the chain mixing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acumen_length</th>\n",
       "      <th>basal_L_widest_point</th>\n",
       "      <th>lateral_lft_W</th>\n",
       "      <th>basal_petiolule</th>\n",
       "      <th>stip_scar_length</th>\n",
       "      <th>X2o_vein_pairs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiv</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF175</th>\n",
       "      <td>5.82</td>\n",
       "      <td>29.32</td>\n",
       "      <td>36.79</td>\n",
       "      <td>8.98</td>\n",
       "      <td>2.30</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF328</th>\n",
       "      <td>7.57</td>\n",
       "      <td>26.59</td>\n",
       "      <td>33.04</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.39</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF200</th>\n",
       "      <td>1.59</td>\n",
       "      <td>23.89</td>\n",
       "      <td>27.35</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.78</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF209</th>\n",
       "      <td>2.99</td>\n",
       "      <td>19.32</td>\n",
       "      <td>30.80</td>\n",
       "      <td>4.94</td>\n",
       "      <td>2.04</td>\n",
       "      <td>10.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14528</th>\n",
       "      <td>7.50</td>\n",
       "      <td>17.39</td>\n",
       "      <td>33.91</td>\n",
       "      <td>9.12</td>\n",
       "      <td>2.99</td>\n",
       "      <td>10.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF276</th>\n",
       "      <td>6.54</td>\n",
       "      <td>26.16</td>\n",
       "      <td>37.79</td>\n",
       "      <td>8.35</td>\n",
       "      <td>2.64</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF286</th>\n",
       "      <td>6.49</td>\n",
       "      <td>25.38</td>\n",
       "      <td>52.27</td>\n",
       "      <td>11.73</td>\n",
       "      <td>2.75</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14504</th>\n",
       "      <td>7.64</td>\n",
       "      <td>17.71</td>\n",
       "      <td>48.74</td>\n",
       "      <td>5.32</td>\n",
       "      <td>2.82</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14505</th>\n",
       "      <td>11.66</td>\n",
       "      <td>29.61</td>\n",
       "      <td>54.47</td>\n",
       "      <td>5.67</td>\n",
       "      <td>3.00</td>\n",
       "      <td>17.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14506</th>\n",
       "      <td>14.81</td>\n",
       "      <td>29.22</td>\n",
       "      <td>70.34</td>\n",
       "      <td>13.51</td>\n",
       "      <td>3.50</td>\n",
       "      <td>20.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13103</th>\n",
       "      <td>9.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.19</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13101</th>\n",
       "      <td>7.92</td>\n",
       "      <td>29.42</td>\n",
       "      <td>48.27</td>\n",
       "      <td>13.92</td>\n",
       "      <td>1.98</td>\n",
       "      <td>14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF155</th>\n",
       "      <td>9.96</td>\n",
       "      <td>31.90</td>\n",
       "      <td>30.46</td>\n",
       "      <td>6.67</td>\n",
       "      <td>2.94</td>\n",
       "      <td>14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14482</th>\n",
       "      <td>5.70</td>\n",
       "      <td>41.05</td>\n",
       "      <td>73.60</td>\n",
       "      <td>11.41</td>\n",
       "      <td>4.08</td>\n",
       "      <td>20.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14483</th>\n",
       "      <td>7.41</td>\n",
       "      <td>38.27</td>\n",
       "      <td>77.65</td>\n",
       "      <td>7.13</td>\n",
       "      <td>4.55</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14477</th>\n",
       "      <td>8.75</td>\n",
       "      <td>25.58</td>\n",
       "      <td>47.23</td>\n",
       "      <td>13.50</td>\n",
       "      <td>2.93</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14478</th>\n",
       "      <td>12.78</td>\n",
       "      <td>31.74</td>\n",
       "      <td>63.04</td>\n",
       "      <td>12.94</td>\n",
       "      <td>3.14</td>\n",
       "      <td>16.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14480</th>\n",
       "      <td>9.88</td>\n",
       "      <td>32.51</td>\n",
       "      <td>45.39</td>\n",
       "      <td>8.04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14485</th>\n",
       "      <td>7.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.89</td>\n",
       "      <td>7.71</td>\n",
       "      <td>2.55</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14501</th>\n",
       "      <td>7.80</td>\n",
       "      <td>24.09</td>\n",
       "      <td>43.06</td>\n",
       "      <td>10.25</td>\n",
       "      <td>2.39</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D14513</th>\n",
       "      <td>8.54</td>\n",
       "      <td>23.27</td>\n",
       "      <td>39.38</td>\n",
       "      <td>13.11</td>\n",
       "      <td>2.82</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13090</th>\n",
       "      <td>18.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.31</td>\n",
       "      <td>13.39</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13097</th>\n",
       "      <td>11.67</td>\n",
       "      <td>19.45</td>\n",
       "      <td>64.28</td>\n",
       "      <td>11.66</td>\n",
       "      <td>5.38</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D12950</th>\n",
       "      <td>15.39</td>\n",
       "      <td>14.64</td>\n",
       "      <td>42.25</td>\n",
       "      <td>6.32</td>\n",
       "      <td>1.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13063</th>\n",
       "      <td>3.16</td>\n",
       "      <td>21.69</td>\n",
       "      <td>25.77</td>\n",
       "      <td>8.71</td>\n",
       "      <td>2.55</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D12963</th>\n",
       "      <td>2.40</td>\n",
       "      <td>18.23</td>\n",
       "      <td>23.91</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.63</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF160</th>\n",
       "      <td>4.71</td>\n",
       "      <td>10.13</td>\n",
       "      <td>21.28</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.28</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF327</th>\n",
       "      <td>5.71</td>\n",
       "      <td>17.75</td>\n",
       "      <td>28.00</td>\n",
       "      <td>5.34</td>\n",
       "      <td>2.22</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF224</th>\n",
       "      <td>1.50</td>\n",
       "      <td>26.63</td>\n",
       "      <td>33.61</td>\n",
       "      <td>7.66</td>\n",
       "      <td>2.75</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF228</th>\n",
       "      <td>4.00</td>\n",
       "      <td>15.61</td>\n",
       "      <td>21.82</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>8.83</td>\n",
       "      <td>21.86</td>\n",
       "      <td>46.03</td>\n",
       "      <td>10.69</td>\n",
       "      <td>2.47</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13052</th>\n",
       "      <td>7.12</td>\n",
       "      <td>20.81</td>\n",
       "      <td>33.75</td>\n",
       "      <td>6.61</td>\n",
       "      <td>2.35</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF153</th>\n",
       "      <td>9.22</td>\n",
       "      <td>36.38</td>\n",
       "      <td>31.56</td>\n",
       "      <td>8.04</td>\n",
       "      <td>3.78</td>\n",
       "      <td>12.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF164</th>\n",
       "      <td>3.98</td>\n",
       "      <td>12.57</td>\n",
       "      <td>18.27</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2.86</td>\n",
       "      <td>12.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D13075</th>\n",
       "      <td>3.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.02</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF197</th>\n",
       "      <td>3.91</td>\n",
       "      <td>22.46</td>\n",
       "      <td>44.60</td>\n",
       "      <td>5.80</td>\n",
       "      <td>3.21</td>\n",
       "      <td>11.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acumen_length  basal_L_widest_point  lateral_lft_W  basal_petiolule  \\\n",
       "Indiv                                                                         \n",
       "SF175            5.82                 29.32          36.79             8.98   \n",
       "SF328            7.57                 26.59          33.04             5.40   \n",
       "SF200            1.59                 23.89          27.35             4.63   \n",
       "SF209            2.99                 19.32          30.80             4.94   \n",
       "D14528           7.50                 17.39          33.91             9.12   \n",
       "SF276            6.54                 26.16          37.79             8.35   \n",
       "SF286            6.49                 25.38          52.27            11.73   \n",
       "D14504           7.64                 17.71          48.74             5.32   \n",
       "D14505          11.66                 29.61          54.47             5.67   \n",
       "D14506          14.81                 29.22          70.34            13.51   \n",
       "D13103           9.16                   NaN          44.31              NaN   \n",
       "D13101           7.92                 29.42          48.27            13.92   \n",
       "SF155            9.96                 31.90          30.46             6.67   \n",
       "D14482           5.70                 41.05          73.60            11.41   \n",
       "D14483           7.41                 38.27          77.65             7.13   \n",
       "D14477           8.75                 25.58          47.23            13.50   \n",
       "D14478          12.78                 31.74          63.04            12.94   \n",
       "D14480           9.88                 32.51          45.39             8.04   \n",
       "D14485           7.34                   NaN          32.89             7.71   \n",
       "D14501           7.80                 24.09          43.06            10.25   \n",
       "D14513           8.54                 23.27          39.38            13.11   \n",
       "D13090          18.25                   NaN          37.31            13.39   \n",
       "D13097          11.67                 19.45          64.28            11.66   \n",
       "D12950          15.39                 14.64          42.25             6.32   \n",
       "D13063           3.16                 21.69          25.77             8.71   \n",
       "D12963           2.40                 18.23          23.91             7.05   \n",
       "SF160            4.71                 10.13          21.28             2.43   \n",
       "SF327            5.71                 17.75          28.00             5.34   \n",
       "SF224            1.50                 26.63          33.61             7.66   \n",
       "SF228            4.00                 15.61          21.82             3.80   \n",
       "5573             8.83                 21.86          46.03            10.69   \n",
       "D13052           7.12                 20.81          33.75             6.61   \n",
       "SF153            9.22                 36.38          31.56             8.04   \n",
       "SF164            3.98                 12.57          18.27             3.53   \n",
       "D13075           3.17                   NaN          53.70              NaN   \n",
       "SF197            3.91                 22.46          44.60             5.80   \n",
       "\n",
       "        stip_scar_length  X2o_vein_pairs  \n",
       "Indiv                                     \n",
       "SF175               2.30           10.67  \n",
       "SF328               1.39           10.50  \n",
       "SF200               1.78           10.00  \n",
       "SF209               2.04           10.67  \n",
       "D14528              2.99           10.33  \n",
       "SF276               2.64            8.00  \n",
       "SF286               2.75            8.50  \n",
       "D14504              2.82           16.67  \n",
       "D14505              3.00           17.50  \n",
       "D14506              3.50           20.33  \n",
       "D13103              3.19           17.00  \n",
       "D13101              1.98           14.50  \n",
       "SF155               2.94           14.50  \n",
       "D14482              4.08           20.33  \n",
       "D14483              4.55           21.00  \n",
       "D14477              2.93           16.67  \n",
       "D14478              3.14           16.33  \n",
       "D14480              1.75           18.33  \n",
       "D14485              2.55           15.00  \n",
       "D14501              2.39           17.33  \n",
       "D14513              2.82           16.00  \n",
       "D13090              4.00           16.00  \n",
       "D13097              5.38           15.00  \n",
       "D12950              1.98             NaN  \n",
       "D13063              2.55           10.50  \n",
       "D12963              1.63            8.00  \n",
       "SF160               2.28           11.50  \n",
       "SF327               2.22           10.00  \n",
       "SF224               2.75           12.50  \n",
       "SF228               1.27            9.33  \n",
       "5573                2.47           15.00  \n",
       "D13052              2.35           12.50  \n",
       "SF153               3.78           12.67  \n",
       "SF164               2.86           12.33  \n",
       "D13075              3.02           13.00  \n",
       "SF197               3.21           11.33  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trait data (csv) from (https://zenodo.../CanEnd_trait2.csv\")\n",
    "TRAITS = pd.read_csv(\"./CanEnd_traits.csv\", na_values=\"\", index_col=0)\n",
    "TRAITS.head(10)\n",
    "\n",
    "## select a subset of traits for this test\n",
    "subt = TRAITS[['acumen_length', 'basal_L_widest_point', 'lateral_lft_W',\n",
    "               'basal_petiolule','stip_scar_length', 'X2o_vein_pairs']]\n",
    "subt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ctl file\n",
      "--------\n",
      "seed = 502852\n",
      "seqfile = /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/ibpp-test.ibpp.seq.txt\n",
      "Imapfile = /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/ibpp-test.ibpp.imap.txt\n",
      "mcmcfile = /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/ibpp-test.ibpp.mcmc.txt\n",
      "outfile = /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/ibpp-test.ibpp.out.txt\n",
      "traitfile = /ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/ibpp-test.ibpp.traits.txt\n",
      "nloci = 300\n",
      "cleandata = 0\n",
      "speciesdelimitation = 1 1 2 1\n",
      "ntraits = 6\n",
      "nindT = 36\n",
      "usetraitdata = 1\n",
      "useseqdata = 1\n",
      "nu0 = 0\n",
      "kappa0 = 0\n",
      "species&tree = 6 A B C D E F\n",
      "                 9 4 3 6 2 13\n",
      "                 ((((D,C),B),(E,F)),A);\n",
      "thetaprior = 2 2000\n",
      "tauprior = 2 2000 1\n",
      "finetune = 1: 300.0 0.0002 0.0001 0.0001 0.2 0.0001 0.1 0.1\n",
      "print = 1 0 0 0\n",
      "burnin = 100\n",
      "sampfreq = 2\n",
      "nsample = 1000\n",
      "--------\n",
      "\n",
      "new files created (300 loci, 6 species, 37 samples)\n",
      "  ibpp-test.ibpp.seq.txt\n",
      "  ibpp-test.ibpp.imap.txt\n",
      "  ibpp-test.ibpp.ctl.txt\n",
      "  ibpp-test.ibpp.traits.txt\n"
     ]
    }
   ],
   "source": [
    "## this is to show an example ctl file (our actual runs are below)\n",
    "## This and variants of it were used to find optimal finetune params.\n",
    "ctl1 = ip.file_conversion.loci2bpp(\"ibpp-test\", \n",
    "                                   locifile=LOCI, \n",
    "                                   traits_df=subt,\n",
    "                                   imap=IMAP6, \n",
    "                                   guidetree=TREE6, \n",
    "                                   minmap=MINMAP6,\n",
    "                                   wdir=WDIR,\n",
    "                                   infer_sptree=0,\n",
    "                                   infer_delimit=1,\n",
    "                                   delimit_alg=(1, 2, 1),\n",
    "                                   maxloci=300,  \n",
    "                                   nsample=1000,\n",
    "                                   burnin=100,\n",
    "                                   sampfreq=2,\n",
    "                                   thetaprior=(2, 2000),\n",
    "                                   tauprior=(2, 2000, 1),\n",
    "                                   finetune=(300.0, 0.0002, 0.0001, 0.0001, 0.2, 0.0001, 0.1, 0.1),\n",
    "                                   seed=random.randint(1,1e6),\n",
    "                                   verbose=1,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up many additional species delimitation tests\n",
    "We are interested in both how well the sequence data and the trait data can delimit species in Canarium. We will setup a range of tests to look at different settings for the priors, for different species delimitation algorithms, and for different types of data. We will start with a six taxon tree and allow the species delimitation algorithm to collapes nodes on the tree to test hypotheses of 1-6 species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set up a couple tests to perform over different delimitation algorithms\n",
    "DELIMIT_TESTS = [\n",
    "    (0, 2),\n",
    "    (0, 5),\n",
    "    (1, 1.0, 2.0),\n",
    "    (1, 2.0, 1.0), \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-0-tr-0-rep-0.ibpp.seq.txt\n",
      "  delim-alg-0-tr-0-rep-0.ibpp.imap.txt\n",
      "  delim-alg-0-tr-0-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-0-tr-0-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-0-tr-0-rep-1.ibpp.seq.txt\n",
      "  delim-alg-0-tr-0-rep-1.ibpp.imap.txt\n",
      "  delim-alg-0-tr-0-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-0-tr-0-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-0-tr-1-rep-0.ibpp.seq.txt\n",
      "  delim-alg-0-tr-1-rep-0.ibpp.imap.txt\n",
      "  delim-alg-0-tr-1-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-0-tr-1-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-0-tr-1-rep-1.ibpp.seq.txt\n",
      "  delim-alg-0-tr-1-rep-1.ibpp.imap.txt\n",
      "  delim-alg-0-tr-1-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-0-tr-1-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-1-tr-0-rep-0.ibpp.seq.txt\n",
      "  delim-alg-1-tr-0-rep-0.ibpp.imap.txt\n",
      "  delim-alg-1-tr-0-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-1-tr-0-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-1-tr-0-rep-1.ibpp.seq.txt\n",
      "  delim-alg-1-tr-0-rep-1.ibpp.imap.txt\n",
      "  delim-alg-1-tr-0-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-1-tr-0-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-1-tr-1-rep-0.ibpp.seq.txt\n",
      "  delim-alg-1-tr-1-rep-0.ibpp.imap.txt\n",
      "  delim-alg-1-tr-1-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-1-tr-1-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-1-tr-1-rep-1.ibpp.seq.txt\n",
      "  delim-alg-1-tr-1-rep-1.ibpp.imap.txt\n",
      "  delim-alg-1-tr-1-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-1-tr-1-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-2-tr-0-rep-0.ibpp.seq.txt\n",
      "  delim-alg-2-tr-0-rep-0.ibpp.imap.txt\n",
      "  delim-alg-2-tr-0-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-2-tr-0-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-2-tr-0-rep-1.ibpp.seq.txt\n",
      "  delim-alg-2-tr-0-rep-1.ibpp.imap.txt\n",
      "  delim-alg-2-tr-0-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-2-tr-0-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-2-tr-1-rep-0.ibpp.seq.txt\n",
      "  delim-alg-2-tr-1-rep-0.ibpp.imap.txt\n",
      "  delim-alg-2-tr-1-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-2-tr-1-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-2-tr-1-rep-1.ibpp.seq.txt\n",
      "  delim-alg-2-tr-1-rep-1.ibpp.imap.txt\n",
      "  delim-alg-2-tr-1-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-2-tr-1-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-3-tr-0-rep-0.ibpp.seq.txt\n",
      "  delim-alg-3-tr-0-rep-0.ibpp.imap.txt\n",
      "  delim-alg-3-tr-0-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-3-tr-0-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-3-tr-0-rep-1.ibpp.seq.txt\n",
      "  delim-alg-3-tr-0-rep-1.ibpp.imap.txt\n",
      "  delim-alg-3-tr-0-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-3-tr-0-rep-1.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-3-tr-1-rep-0.ibpp.seq.txt\n",
      "  delim-alg-3-tr-1-rep-0.ibpp.imap.txt\n",
      "  delim-alg-3-tr-1-rep-0.ibpp.ctl.txt\n",
      "  delim-alg-3-tr-1-rep-0.ibpp.traits.txt\n",
      "new files created (1088 loci, 6 species, 37 samples)\n",
      "  delim-alg-3-tr-1-rep-1.ibpp.seq.txt\n",
      "  delim-alg-3-tr-1-rep-1.ibpp.imap.txt\n",
      "  delim-alg-3-tr-1-rep-1.ibpp.ctl.txt\n",
      "  delim-alg-3-tr-1-rep-1.ibpp.traits.txt\n"
     ]
    }
   ],
   "source": [
    "## iterate over combinations for a total of 42 tests. \n",
    "## (1) 4 delimitation algorithm combinations (DELIMIT_TESTS)\n",
    "## (2) 0/1 with or without traits \n",
    "## (3) 2 independent replicates from different random seeds\n",
    "\n",
    "ctls = []\n",
    "for tdx, delim in enumerate(DELIMIT_TESTS):\n",
    "    for usetraits in [0, 1]:\n",
    "        for rep in range(2):\n",
    "        \n",
    "            ## make a name for this test\n",
    "            rname = \"delim-alg-{}-tr-{}-rep-{}\".format(tdx, usetraits, rep)\n",
    "        \n",
    "            ## make input files and get ctl path\n",
    "            ctl = ip.file_conversion.loci2bpp(rname, LOCI, IMAP6, TREE6, \n",
    "                                          wdir=WDIR,\n",
    "                                          traits_df=TRAITS,\n",
    "                                          minmap=MINMAP6, \n",
    "                                          infer_delimit=1,\n",
    "                                          infer_sptree=0,\n",
    "                                          delimit_alg=delim,\n",
    "                                          maxloci=10000,  \n",
    "                                          nsample=200000,\n",
    "                                          burnin=20000,\n",
    "                                          sampfreq=2,\n",
    "                                          thetaprior=(2, 2000),\n",
    "                                          tauprior=(2, 2000, 1),\n",
    "                                          usetraitdata=usetraits,\n",
    "                                          seed=random.randint(0, 1e9),\n",
    "                                          finetune=(300.0, 0.0002, 0.0001, 0.0001, 0.2, 0.0001, 0.1, 0.1),\n",
    "                                          )\n",
    "            ## store ctl finenames\n",
    "            ctls.append(ctl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-0-tr-0-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-0-tr-0-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-0-tr-1-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-0-tr-1-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-1-tr-0-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-1-tr-0-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-1-tr-1-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-1-tr-1-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-2-tr-0-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-2-tr-0-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-2-tr-1-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-2-tr-1-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-3-tr-0-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-3-tr-0-rep-1.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-3-tr-1-rep-0.ibpp.ctl.txt]\n",
      "job submitted [/ysm-gpfs/home/de243/Canarium-GBS/analysis_bpp/delim-alg-3-tr-1-rep-1.ibpp.ctl.txt]\n"
     ]
    }
   ],
   "source": [
    "## store async results\n",
    "delim_asyncs = {}\n",
    "\n",
    "## send jobs to run on cluster\n",
    "for job in ctls:\n",
    "    delim_asyncs[job] = lbview.apply(bpp, job)\n",
    "    sys.stderr.write(\"job submitted [{}]\\n\".format(job))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  delim-alg-0-tr-0-rep-0.ibpp.ctl.txt -- still running\n",
      "1  delim-alg-0-tr-0-rep-1.ibpp.ctl.txt -- still running\n",
      "2  delim-alg-0-tr-1-rep-0.ibpp.ctl.txt -- still running\n",
      "3  delim-alg-0-tr-1-rep-1.ibpp.ctl.txt -- still running\n",
      "4  delim-alg-1-tr-0-rep-0.ibpp.ctl.txt -- still running\n",
      "5  delim-alg-1-tr-0-rep-1.ibpp.ctl.txt -- still running\n",
      "6  delim-alg-1-tr-1-rep-0.ibpp.ctl.txt -- still running\n",
      "7  delim-alg-1-tr-1-rep-1.ibpp.ctl.txt -- still running\n",
      "8  delim-alg-2-tr-0-rep-0.ibpp.ctl.txt -- still running\n",
      "9  delim-alg-2-tr-0-rep-1.ibpp.ctl.txt -- still running\n",
      "10 delim-alg-2-tr-1-rep-0.ibpp.ctl.txt -- still running\n",
      "11 delim-alg-2-tr-1-rep-1.ibpp.ctl.txt -- still running\n",
      "12 delim-alg-3-tr-0-rep-0.ibpp.ctl.txt -- still running\n",
      "13 delim-alg-3-tr-0-rep-1.ibpp.ctl.txt -- still running\n",
      "14 delim-alg-3-tr-1-rep-0.ibpp.ctl.txt -- still running\n",
      "15 delim-alg-3-tr-1-rep-1.ibpp.ctl.txt -- still running\n"
     ]
    }
   ],
   "source": [
    "## check success/failure of all jobs\n",
    "alljobs = dict(delim_asyncs.items())\n",
    "\n",
    "## check whether each has finished or failed\n",
    "for jid, job in enumerate(sorted(alljobs)):\n",
    "    ## get shorter name for job\n",
    "    jobname = job.split(\"/\")[-1]\n",
    "    \n",
    "    ## print done or not\n",
    "    if alljobs[job].ready():\n",
    "        if alljobs[job].successful():\n",
    "            print \"{:<3}{:<30} -- finished\".format(jid, jobname)\n",
    "        else:\n",
    "            print \"{:<3}{:<30} -- failed:\".format(jid, alljobs[job].exception())\n",
    "    else:\n",
    "        print \"{:<3}{:<30} -- still running\".format(jid, jobname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-0-theta-200-rep-1.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-0-theta-20-rep-1.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-1-theta-20-rep-0.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-1-theta-20-rep-2.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-1-theta-20-rep-1.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-0-theta-200-rep-2.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-2-theta-20-rep-0.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-2-theta-20-rep-2.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-1-theta-200-rep-0.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-2-theta-200-rep-1.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-1-theta-200-rep-2.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-2-theta-200-rep-0.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-0-theta-20-rep-0.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-0-theta-200-rep-0.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-0-theta-20-rep-2.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-2-theta-200-rep-2.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-1-theta-200-rep-1.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 02:40 analysis_bpp/tree-2-theta-20-rep-1.bpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-0-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-1-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-0-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-2-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-0-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-3-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-1-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-2-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-2-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-2-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-1-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-5-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-4-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-6-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-5-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-1-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-5-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-4-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-6-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-6-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-4-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-0-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-4-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-6-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-1-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-5-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-5-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-5-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-6-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-6-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-3-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-3-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-4-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-0-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-0-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-1-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-2-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-4-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-3-rep-0.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-2-rep-1.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-1-tr-3-rep-2.ibpp.mcmc.txt\r\n",
      "-rw-r--r-- 1 de243 0 Dec  5 03:03 analysis_bpp/delim-alg-0-tr-3-rep-1.ibpp.mcmc.txt\r\n"
     ]
    }
   ],
   "source": [
    "ll -thr analysis_bpp/*.mcmc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse results (out.txt) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's read in the '.bpp.out.txt' results files for each test\n",
    "median_dict = {}\n",
    "ess_dict = {}\n",
    "\n",
    "for test, job in enumerate(sorted(asyncs)):\n",
    "    ## replace .ctl.txt with .out.txt\n",
    "    outname = job.replace(\".ctl.\", \".out.\")\n",
    "    \n",
    "    ## parse theta and tau priors from the job name\n",
    "    theta = job.split(\"-\")[1:3]\n",
    "    tau = job.split(\"-\")[3:5]\n",
    "    \n",
    "    ## read the file and parse out results\n",
    "    with open(outname, 'r') as infile:\n",
    "        data = infile.readlines()\n",
    "    \n",
    "    ## b/c sptree and delimit were set to 0 all this test did was infer sptree params\n",
    "    ## on the fixed tree. So let's compare the parameters under different priors\n",
    "    for line in data:\n",
    "        if \"theta_1\" and \"theta_2\" in line:\n",
    "            index = [\"theta mean\", \"tau mean\"] + line.split()\n",
    "            \n",
    "        if \"median\" in line:\n",
    "            data = [5./float(theta[1]), 1./float(tau[1])] + line.split()[1:]\n",
    "            median_dict[test] = pd.Series(data=data, index=index)\n",
    "            \n",
    "        if \"ESS*\" in line:\n",
    "            data = [5./float(theta[1]), 1./float(tau[1])] + line.split()[1:]\n",
    "            ess_dict[test] = pd.Series(data=data, index=index)\n",
    "\n",
    "## make results into a dataframe and print. It appears that the prior has a large effect on theta5 (AB)\n",
    "medians = pd.DataFrame(data=median_dict)\n",
    "ess = pd.DataFrame(data=ess_dict)\n",
    "\n",
    "## look at median values\n",
    "medians.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
